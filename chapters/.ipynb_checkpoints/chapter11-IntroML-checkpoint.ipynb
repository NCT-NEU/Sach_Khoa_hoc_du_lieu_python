{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chương: Tổng quan về xây dựng mô hình trên dữ liệu\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giới thiệu\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Học máy là về việc trích xuất kiến thức từ dữ liệu. Đây là một lĩnh vực nghiên cứu nằm ở giao điểm của thống kê, trí tuệ nhân tạo và khoa học máy tính, và còn được biết đến với tên gọi phân tích dự báo hoặc học thống kê. Việc áp dụng các phương pháp học máy trong những năm gần đây đã trở nên phổ biến trong cuộc sống hàng ngày. Từ việc tự động đề xuất phim để xem, món ăn để đặt hoặc sản phẩm để mua, cho đến radio trực tuyến được cá nhân hóa và nhận dạng bạn bè trong ảnh của bạn, nhiều trang web và thiết bị hiện đại đều có các thuật toán học máy làm cốt lõi. Khi bạn nhìn vào một trang web phức tạp như Facebook, Amazon hoặc Netflix, rất có thể mọi phần của trang web đều chứa nhiều mô hình học máy.\n",
    "\n",
    "Ngoài các ứng dụng thương mại, học máy đã có một ảnh hưởng to lớn đến cách thức nghiên cứu dựa trên dữ liệu được thực hiện ngày nay. Các công cụ được giới thiệu trong cuốn sách này đã được áp dụng cho các vấn đề khoa học đa dạng như tìm hiểu về các ngôi sao, tìm kiếm các hành tinh xa xôi, khám phá các hạt mới, phân tích chuỗi DNA và cung cấp các phương pháp điều trị ung thư được cá nhân hóa.\n",
    "\n",
    "Tuy nhiên, ứng dụng của bạn không cần phải có quy mô lớn hoặc thay đổi thế giới như những ví dụ này để được hưởng lợi từ học máy. Trong chương này, chúng tôi sẽ giải thích tại sao học máy lại trở nên phổ biến và thảo luận về những loại vấn đề nào có thể được giải quyết bằng học máy. Sau đó, chúng tôi sẽ chỉ cho bạn cách xây dựng mô hình học máy đầu tiên của mình, đồng thời giới thiệu các khái niệm quan trọng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tại sao lại là Học máy?\n",
    "\n",
    "Trong những ngày đầu của các ứng dụng “thông minh”, nhiều hệ thống đã sử dụng các quy tắc được mã hóa thủ công gồm các quyết định “if” và “else” để xử lý dữ liệu hoặc điều chỉnh theo đầu vào của người dùng. Hãy nghĩ về một bộ lọc thư rác có nhiệm vụ di chuyển các email đến phù hợp vào thư mục thư rác. Bạn có thể tạo ra một danh sách đen các từ sẽ khiến một email bị đánh dấu là thư rác. Đây sẽ là một ví dụ về việc sử dụng một hệ thống quy tắc do chuyên gia thiết kế để tạo ra một ứng dụng “thông minh”. Việc tạo ra các quy tắc quyết định một cách thủ công là khả thi đối với một số ứng dụng, đặc biệt là những ứng dụng mà con người hiểu rõ về quy trình cần mô hình hóa. Tuy nhiên, việc sử dụng các quy tắc được mã hóa thủ công để đưa ra quyết định có hai nhược điểm lớn:\n",
    "\n",
    "* Logic cần thiết để đưa ra quyết định là đặc thù cho một lĩnh vực và nhiệm vụ duy nhất. Thay đổi nhiệm vụ dù chỉ một chút cũng có thể đòi hỏi phải viết lại toàn bộ hệ thống.\n",
    "* Việc thiết kế các quy tắc đòi hỏi sự hiểu biết sâu sắc về cách một chuyên gia con người nên đưa ra quyết định.\n",
    "\n",
    "Một ví dụ về nơi mà phương pháp mã hóa thủ công này sẽ thất bại là trong việc phát hiện khuôn mặt trong hình ảnh. Ngày nay, mọi điện thoại thông minh đều có thể phát hiện khuôn mặt trong ảnh. Tuy nhiên, việc phát hiện khuôn mặt là một vấn đề chưa được giải quyết cho đến tận năm 2001. Vấn đề chính là cách mà các pixel (tạo nên một hình ảnh trong máy tính) được máy tính “nhận thức” rất khác so với cách con người nhận thức một khuôn mặt. Sự khác biệt này trong cách biểu diễn khiến cho con người gần như không thể đưa ra một bộ quy tắc tốt để mô tả những gì cấu thành một khuôn mặt trong một hình ảnh kỹ thuật số.\n",
    "\n",
    "Tuy nhiên, với học máy, chỉ cần cung cấp cho một chương trình một bộ sưu tập lớn các hình ảnh về khuôn mặt là đủ để một thuật toán xác định những đặc điểm nào là cần thiết để nhận dạng một khuôn mặt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các vấn đề Học máy có thể giải quyết\n",
    "\n",
    "Các loại thuật toán học máy thành công nhất là những thuật toán tự động hóa các quy trình ra quyết định bằng cách tổng quát hóa từ các ví dụ đã biết. Trong bối cảnh này, được gọi là **học có giám sát**, người dùng cung cấp cho thuật toán các cặp đầu vào và đầu ra mong muốn, và thuật toán sẽ tìm ra cách để tạo ra đầu ra mong muốn với một đầu vào cho trước. Cụ thể, thuật toán có thể tạo ra một đầu ra cho một đầu vào mà nó chưa từng thấy trước đây mà không cần sự giúp đỡ của con người. Quay trở lại ví dụ về phân loại thư rác, sử dụng học máy, người dùng cung cấp cho thuật toán một số lượng lớn email (là đầu vào), cùng với thông tin về việc liệu bất kỳ email nào trong số này có phải là thư rác hay không (là đầu ra mong muốn). Với một email mới, thuật toán sau đó sẽ đưa ra dự đoán về việc email mới có phải là thư rác hay không.\n",
    "\n",
    "Các thuật toán học máy học từ các cặp đầu vào/đầu ra được gọi là thuật toán học có giám sát vì có một “giáo viên” cung cấp sự giám sát cho các thuật toán dưới dạng các đầu ra mong muốn cho mỗi ví dụ mà chúng học. Mặc dù việc tạo ra một tập dữ liệu đầu vào và đầu ra thường là một quá trình thủ công tốn nhiều công sức, các thuật toán học có giám sát được hiểu rõ và hiệu suất của chúng rất dễ đo lường. Nếu ứng dụng của bạn có thể được xây dựng thành một bài toán học có giám sát và bạn có thể tạo ra một tập dữ liệu bao gồm kết quả mong muốn, thì học máy có khả năng giải quyết được vấn đề của bạn.\n",
    "\n",
    "Các ví dụ về nhiệm vụ học máy có giám sát bao gồm:\n",
    "\n",
    "**Xác định mã zip từ các chữ số viết tay trên phong bì**\n",
    "Ở đây, đầu vào là một bản quét của chữ viết tay và đầu ra mong muốn là các chữ số thực tế trong mã zip. Để tạo một tập dữ liệu để xây dựng mô hình học máy, bạn cần thu thập nhiều phong bì. Sau đó, bạn có thể tự đọc các mã zip và lưu trữ các chữ số làm kết quả mong muốn của mình.\n",
    "\n",
    "**Xác định xem một khối u có lành tính hay không dựa trên hình ảnh y tế**\n",
    "Ở đây, đầu vào là hình ảnh và đầu ra là liệu khối u có lành tính hay không. Để tạo một tập dữ liệu để xây dựng mô hình, bạn cần một cơ sở dữ liệu hình ảnh y tế. Bạn cũng cần ý kiến chuyên gia, vì vậy một bác sĩ cần phải xem tất cả các hình ảnh và quyết định khối u nào là lành tính và khối u nào không. Thậm chí có thể cần phải thực hiện chẩn đoán bổ sung ngoài nội dung của hình ảnh để xác định xem khối u trong hình ảnh có phải là ung thư hay không.\n",
    "\n",
    "**Phát hiện hoạt động gian lận trong các giao dịch thẻ tín dụng**\n",
    "Ở đây, đầu vào là một bản ghi của giao dịch thẻ tín dụng và đầu ra là liệu nó có khả năng là gian lận hay không. Giả sử bạn là đơn vị phát hành thẻ tín dụng, việc thu thập tập dữ liệu có nghĩa là lưu trữ tất cả các giao dịch và ghi lại nếu người dùng báo cáo bất kỳ giao dịch nào là gian lận.\n",
    "\n",
    "Một điều thú vị cần lưu ý về những ví dụ này là mặc dù đầu vào và đầu ra trông khá đơn giản, quy trình thu thập dữ liệu cho ba nhiệm vụ này lại rất khác nhau. Trong khi việc đọc phong bì tốn nhiều công sức, nó lại dễ dàng và rẻ. Mặt khác, việc có được hình ảnh y tế và chẩn đoán không chỉ đòi hỏi máy móc đắt tiền mà còn cả kiến thức chuyên môn hiếm và đắt đỏ, chưa kể đến các mối quan tâm về đạo đức và quyền riêng tư. Trong ví dụ về phát hiện gian lận thẻ tín dụng, việc thu thập dữ liệu đơn giản hơn nhiều. Khách hàng của bạn sẽ cung cấp cho bạn đầu ra mong muốn, vì họ sẽ báo cáo gian lận. Tất cả những gì bạn phải làm để có được các cặp đầu vào/đầu ra của hoạt động gian lận và không gian lận là chờ đợi.\n",
    "\n",
    "**Thuật toán không giám sát** là loại thuật toán khác mà chúng tôi sẽ đề cập trong cuốn sách này. Trong học không giám sát, chỉ có dữ liệu đầu vào được biết đến và không có dữ liệu đầu ra nào được cung cấp cho thuật toán. Mặc dù có nhiều ứng dụng thành công của các phương pháp này, chúng thường khó hiểu và khó đánh giá hơn.\n",
    "\n",
    "Các ví dụ về học không giám sát bao gồm:\n",
    "\n",
    "**Xác định các chủ đề trong một tập hợp các bài đăng trên blog**\n",
    "Nếu bạn có một bộ sưu tập lớn dữ liệu văn bản, bạn có thể muốn tóm tắt nó và tìm các chủ đề phổ biến trong đó. Bạn có thể không biết trước những chủ đề này là gì, hoặc có bao nhiêu chủ đề. Do đó, không có đầu ra nào được biết đến.\n",
    "\n",
    "**Phân khúc khách hàng thành các nhóm có sở thích tương tự**\n",
    "Với một tập hợp hồ sơ khách hàng, bạn có thể muốn xác định những khách hàng nào giống nhau và liệu có các nhóm khách hàng có sở thích tương tự hay không. Đối với một trang web mua sắm, đó có thể là “phụ huynh”, “mọt sách” hoặc “game thủ”. Vì bạn không biết trước những nhóm này có thể là gì, hoặc thậm chí có bao nhiêu nhóm, bạn không có đầu ra nào được biết đến.\n",
    "\n",
    "**Phát hiện các mẫu truy cập bất thường vào một trang web**\n",
    "Để xác định hành vi lạm dụng hoặc lỗi, việc tìm ra các mẫu truy cập khác với bình thường thường rất hữu ích. Mỗi mẫu bất thường có thể rất khác nhau và bạn có thể không có bất kỳ trường hợp nào được ghi nhận về hành vi bất thường. Bởi vì trong ví dụ này bạn chỉ quan sát lưu lượng truy cập và bạn không biết điều gì cấu thành hành vi bình thường và bất thường, đây là một bài toán không giám sát.\n",
    "\n",
    "Đối với cả nhiệm vụ học có giám sát và không giám sát, điều quan trọng là phải có một biểu diễn dữ liệu đầu vào của bạn mà máy tính có thể hiểu được. Thường thì việc nghĩ về dữ liệu của bạn như một bảng sẽ hữu ích. Mỗi điểm dữ liệu mà bạn muốn suy luận (mỗi email, mỗi khách hàng, mỗi giao dịch) là một hàng, và mỗi thuộc tính mô tả điểm dữ liệu đó (chẳng hạn như tuổi của khách hàng hoặc số tiền hoặc vị trí của một giao dịch) là một cột. Bạn có thể mô tả người dùng bằng tuổi, giới tính, thời điểm họ tạo tài khoản và tần suất họ mua hàng từ cửa hàng trực tuyến của bạn. Bạn có thể mô tả hình ảnh của một khối u bằng các giá trị thang độ xám của mỗi pixel, hoặc có thể bằng cách sử dụng kích thước, hình dạng và màu sắc của khối u.\n",
    "\n",
    "Mỗi thực thể hoặc hàng ở đây được gọi là một **mẫu** (hoặc điểm dữ liệu) trong học máy, trong khi các cột—các thuộc tính mô tả những thực thể này—được gọi là **đặc trưng**.\n",
    "\n",
    "Sau này trong cuốn sách này, chúng ta sẽ đi sâu hơn vào chủ đề xây dựng một biểu diễn tốt cho dữ liệu của bạn, được gọi là **trích xuất đặc trưng** hoặc **kỹ thuật đặc trưng**. Tuy nhiên, bạn nên ghi nhớ rằng không có thuật toán học máy nào có thể đưa ra dự đoán về dữ liệu mà nó không có thông tin. Ví dụ, nếu đặc trưng duy nhất bạn có cho một bệnh nhân là họ của họ, không có thuật toán nào có thể dự đoán giới tính của họ. Thông tin này đơn giản là không có trong dữ liệu của bạn. Nếu bạn thêm một đặc trưng khác chứa tên của bệnh nhân, bạn sẽ may mắn hơn nhiều, vì thường có thể biết được giới tính qua tên của một người."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiểu rõ Nhiệm vụ và Dữ liệu của bạn\n",
    "\n",
    "Có lẽ phần quan trọng nhất trong quy trình học máy là hiểu rõ dữ liệu bạn đang làm việc và mối quan hệ của nó với nhiệm vụ bạn muốn giải quyết. Sẽ không hiệu quả nếu bạn chọn một thuật toán một cách ngẫu nhiên và đưa dữ liệu của mình vào đó. Cần phải hiểu những gì đang diễn ra trong tập dữ liệu của bạn trước khi bạn bắt đầu xây dựng một mô hình. Mỗi thuật toán đều khác nhau về loại dữ liệu và bối cảnh vấn đề mà nó hoạt động tốt nhất. Khi bạn đang xây dựng một giải pháp học máy, bạn nên trả lời, hoặc ít nhất là ghi nhớ, các câu hỏi sau:\n",
    "\n",
    "* Câu hỏi tôi đang cố gắng trả lời là gì? Tôi có nghĩ rằng dữ liệu thu thập được có thể trả lời câu hỏi đó không?\n",
    "* Cách tốt nhất để diễn đạt câu hỏi của tôi thành một bài toán học máy là gì?\n",
    "* Tôi đã thu thập đủ dữ liệu để đại diện cho vấn đề tôi muốn giải quyết chưa?\n",
    "* Tôi đã trích xuất những đặc trưng nào của dữ liệu, và liệu những đặc trưng này có cho phép đưa ra những dự đoán đúng đắn không?\n",
    "* Tôi sẽ đo lường thành công trong ứng dụng của mình như thế nào?\n",
    "* Giải pháp học máy sẽ tương tác với các phần khác trong nghiên cứu hoặc sản phẩm kinh doanh của tôi như thế nào?\n",
    "\n",
    "Trong một bối cảnh rộng lớn hơn, các thuật toán và phương pháp trong học máy chỉ là một phần của một quy trình lớn hơn để giải quyết một vấn đề cụ thể, và việc luôn ghi nhớ bức tranh toàn cảnh là điều tốt. Nhiều người dành rất nhiều thời gian để xây dựng các giải pháp học máy phức tạp, chỉ để phát hiện ra rằng chúng không giải quyết đúng vấn đề.\n",
    "\n",
    "Khi đi sâu vào các khía cạnh kỹ thuật của học máy (như chúng ta sẽ làm trong cuốn sách này), rất dễ bị mất đi mục tiêu cuối cùng. Mặc dù chúng tôi sẽ không thảo luận chi tiết về các câu hỏi được liệt kê ở đây, chúng tôi vẫn khuyến khích bạn ghi nhớ tất cả các giả định mà bạn có thể đang đưa ra, một cách rõ ràng hoặc ngầm định, khi bạn bắt đầu xây dựng các mô hình học máy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tại sao lại là Python?\n",
    "\n",
    "Python đã trở thành ngôn ngữ chung cho nhiều ứng dụng khoa học dữ liệu. Nó kết hợp sức mạnh của các ngôn ngữ lập trình đa năng với sự dễ sử dụng của các ngôn ngữ kịch bản chuyên biệt như MATLAB hoặc R. Python có các thư viện để tải dữ liệu, trực quan hóa, thống kê, xử lý ngôn ngữ tự nhiên, xử lý hình ảnh, và nhiều hơn nữa. Hộp công cụ rộng lớn này cung cấp cho các nhà khoa học dữ liệu một loạt lớn các chức năng chung và chuyên dụng. Một trong những ưu điểm chính của việc sử dụng Python là khả năng tương tác trực tiếp với mã, sử dụng một terminal hoặc các công cụ khác như Jupyter Notebook, mà chúng ta sẽ xem xét ngay sau đây. Học máy và phân tích dữ liệu về cơ bản là các quy trình lặp đi lặp lại, trong đó dữ liệu thúc đẩy phân tích. Điều cần thiết cho các quy trình này là có các công cụ cho phép lặp lại nhanh chóng và tương tác dễ dàng.\n",
    "\n",
    "Là một ngôn ngữ lập trình đa năng, Python cũng cho phép tạo ra các giao diện người dùng đồ họa (GUI) và dịch vụ web phức tạp, và để tích hợp vào các hệ thống hiện có."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn\n",
    "\n",
    "**scikit-learn** là một dự án mã nguồn mở, có nghĩa là nó miễn phí để sử dụng và phân phối, và bất kỳ ai cũng có thể dễ dàng lấy mã nguồn để xem những gì đang diễn ra đằng sau. Dự án scikit-learn liên tục được phát triển và cải tiến, và nó có một cộng đồng người dùng rất tích cực. Nó chứa một số thuật toán học máy tiên tiến, cũng như tài liệu toàn diện về mỗi thuật toán. scikit-learn là một công cụ rất phổ biến và là thư viện Python nổi bật nhất cho học máy. Nó được sử dụng rộng rãi trong ngành công nghiệp và học thuật, và có rất nhiều hướng dẫn và đoạn mã có sẵn trực tuyến. scikit-learn hoạt động tốt với một số công cụ Python khoa học khác, mà chúng ta sẽ thảo luận sau trong chương này.\n",
    "\n",
    "Trong khi đọc, chúng tôi khuyên bạn cũng nên duyệt qua hướng dẫn sử dụng và tài liệu API của scikit-learn để biết thêm chi tiết và nhiều tùy chọn hơn cho mỗi thuật toán. Tài liệu trực tuyến rất kỹ lưỡng, và cuốn sách này sẽ cung cấp cho bạn tất cả các kiến thức nền tảng về học máy để hiểu nó một cách chi tiết."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cài đặt scikit-learn\n",
    "\n",
    "scikit-learn phụ thuộc vào hai gói Python khác, **NumPy** và **SciPy**. Để vẽ đồ thị và phát triển tương tác, bạn cũng nên cài đặt **matplotlib**, **IPython** và **Jupyter Notebook**. Chúng tôi khuyên bạn nên sử dụng một trong các bản phân phối Python được đóng gói sẵn sau đây, chúng sẽ cung cấp các gói cần thiết:\n",
    "\n",
    "-   **Anaconda**: Một bản phân phối Python được tạo ra để xử lý dữ liệu quy mô lớn, phân tích dự báo và tính toán khoa học. Anaconda đi kèm với NumPy, SciPy, matplotlib, pandas, IPython, Jupyter Notebook và scikit-learn. Có sẵn trên Mac OS, Windows và Linux, đây là một giải pháp rất tiện lợi và là giải pháp chúng tôi đề xuất cho những người không có sẵn cài đặt các gói Python khoa học. Anaconda hiện cũng bao gồm thư viện Intel MKL thương mại miễn phí. Việc sử dụng MKL (được thực hiện tự động khi Anaconda được cài đặt) có thể cải thiện tốc độ đáng kể cho nhiều thuật toán trong scikit-learn.\n",
    "-   **Enthought Canopy**: Một bản phân phối Python khác cho tính toán khoa học. Nó đi kèm với NumPy, SciPy, matplotlib, pandas và IPython, nhưng phiên bản miễn phí không có scikit-learn. Nếu bạn là thành viên của một tổ chức học thuật, cấp bằng, bạn có thể yêu cầu giấy phép học thuật và được truy cập miễn phí vào phiên bản trả phí của Enthought Canopy. Enthought Canopy có sẵn cho Python 2.7.x và hoạt động trên Mac OS, Windows và Linux.\n",
    "-   **Python(x,y)**: Một bản phân phối Python miễn phí cho tính toán khoa học, đặc biệt cho Windows. Python(x,y) đi kèm với NumPy, SciPy, matplotlib, pandas, IPython và scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu bạn đã có một cài đặt Python, bạn có thể sử dụng `pip` để cài đặt tất cả các gói này:\n",
    "\n",
    "```\n",
    "$ pip install numpy scipy matplotlib ipython scikit-learn pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các Thư viện và Công cụ Thiết yếu\n",
    "\n",
    "Việc hiểu rõ scikit-learn là gì và cách sử dụng nó là rất quan trọng, nhưng có một vài thư viện khác sẽ nâng cao trải nghiệm của bạn. scikit-learn được xây dựng trên nền tảng các thư viện Python khoa học NumPy và SciPy. Ngoài NumPy và SciPy, chúng ta sẽ sử dụng pandas và matplotlib. Chúng ta cũng sẽ giới thiệu Jupyter Notebook, một môi trường lập trình tương tác dựa trên trình duyệt. Tóm lại, đây là những gì bạn nên biết về những công cụ này để tận dụng tối đa scikit-learn.\n",
    "\n",
    "#### Jupyter Notebook\n",
    "\n",
    "Jupyter Notebook là một môi trường tương tác để chạy mã trong trình duyệt. Đây là một công cụ tuyệt vời để phân tích dữ liệu thăm dò và được các nhà khoa học dữ liệu sử dụng rộng rãi. Mặc dù Jupyter Notebook hỗ trợ nhiều ngôn ngữ lập trình, chúng ta chỉ cần hỗ trợ Python. Jupyter Notebook giúp dễ dàng kết hợp mã, văn bản và hình ảnh, và toàn bộ cuốn sách này thực sự được viết dưới dạng một Jupyter Notebook. Tất cả các ví dụ mã mà chúng tôi bao gồm đều có thể được tải xuống từ GitHub.\n",
    "\n",
    "#### NumPy\n",
    "\n",
    "NumPy là một trong những gói cơ bản cho tính toán khoa học trong Python. Nó chứa chức năng cho các mảng đa chiều, các hàm toán học cấp cao như các phép toán đại số tuyến tính và biến đổi Fourier, và các bộ tạo số giả ngẫu nhiên.\n",
    "\n",
    "Trong scikit-learn, mảng NumPy là cấu trúc dữ liệu cơ bản. scikit-learn nhận dữ liệu dưới dạng các mảng NumPy. Bất kỳ dữ liệu nào bạn đang sử dụng đều sẽ phải được chuyển đổi thành một mảng NumPy. Chức năng cốt lõi của NumPy là lớp `ndarray`, một mảng đa chiều (n-chiều). Tất cả các phần tử của mảng phải cùng một loại. Một mảng NumPy trông như thế này:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"x:\\n{}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta sẽ sử dụng NumPy rất nhiều trong cuốn sách này, và chúng ta sẽ gọi các đối tượng của lớp `ndarray` của NumPy là “mảng NumPy” hoặc chỉ là “mảng”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciPy\n",
    "\n",
    "SciPy là một bộ sưu tập các hàm cho tính toán khoa học trong Python. Nó cung cấp, cùng với các chức năng khác, các quy trình đại số tuyến tính nâng cao, tối ưu hóa hàm toán học, xử lý tín hiệu, các hàm toán học đặc biệt và các phân phối thống kê. scikit-learn lấy từ bộ sưu tập các hàm của SciPy để triển khai các thuật toán của nó. Phần quan trọng nhất của SciPy đối với chúng ta là `scipy.sparse`: nó cung cấp các ma trận thưa, là một biểu diễn khác được sử dụng cho dữ liệu trong scikit-learn. Các ma trận thưa được sử dụng bất cứ khi nào chúng ta muốn lưu trữ một mảng 2D chứa chủ yếu là các số không:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mảng NumPy: \n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "# Tạo một mảng NumPy 2D với đường chéo là các số một, và các số không ở mọi nơi khác\n",
    "eye = np.eye(4)\n",
    "print(\"Mảng NumPy: \\n{}\".format(eye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ma trận thưa CSR của SciPy:\n",
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 3)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Chuyển đổi mảng NumPy thành ma trận thưa CSR của SciPy\n",
    "# Chỉ các mục khác không được lưu trữ\n",
    "sparse_matrix = sparse.csr_matrix(eye)\n",
    "print(\"\\nMa trận thưa CSR của SciPy:\\n{}\".format(sparse_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thường thì không thể tạo ra các biểu diễn dày đặc của dữ liệu thưa (vì chúng sẽ không vừa với bộ nhớ), vì vậy chúng ta cần tạo ra các biểu diễn thưa một cách trực tiếp. Đây là một cách để tạo ra cùng một ma trận thưa như trước, sử dụng định dạng COO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biểu diễn COO:\n",
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 3)\t1.0\n"
     ]
    }
   ],
   "source": [
    "data = np.ones(4)\n",
    "row_indices = np.arange(4)\n",
    "col_indices = np.arange(4)\n",
    "eye_coo = sparse.coo_matrix((data, (row_indices, col_indices)))\n",
    "print(\"Biểu diễn COO:\\n{}\".format(eye_coo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### matplotlib\n",
    "\n",
    "**matplotlib** là thư viện vẽ đồ thị khoa học chính trong Python. Nó cung cấp các hàm để tạo ra các hình ảnh trực quan chất lượng xuất bản như biểu đồ đường, biểu đồ cột, biểu đồ phân tán, v.v. Việc trực quan hóa dữ liệu và các khía cạnh khác nhau của phân tích có thể cung cấp cho bạn những hiểu biết quan trọng, và chúng ta sẽ sử dụng matplotlib cho tất cả các hình ảnh trực quan của mình. Khi làm việc trong Jupyter Notebook, bạn có thể hiển thị các hình ảnh trực tiếp trong trình duyệt bằng cách sử dụng các lệnh `%matplotlib notebook` và `%matplotlib inline`. Chúng tôi khuyên bạn nên sử dụng `%matplotlib notebook`, nó cung cấp một môi trường tương tác. Ví dụ, mã này tạo ra biểu đồ trong Hình 1-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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.-Q=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Tạo một chuỗi số từ -10 đến 10 với 100 bước ở giữa\n",
    "x = np.linspace(-10, 10, 100)\n",
    "# Tạo một mảng thứ hai sử dụng sin\n",
    "y = np.sin(x)\n",
    "# Hàm plot tạo một biểu đồ đường của một mảng so với một mảng khác\n",
    "plt.plot(x, y, marker=\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas\n",
    "\n",
    "**pandas** là một thư viện Python để xử lý và phân tích dữ liệu. Nó được xây dựng xung quanh một cấu trúc dữ liệu gọi là `DataFrame` được mô hình hóa theo DataFrame của R. Nói một cách đơn giản, một pandas DataFrame là một bảng, tương tự như một bảng tính Excel. pandas cung cấp một loạt các phương thức để sửa đổi và thao tác trên bảng này; đặc biệt, nó cho phép các truy vấn giống như SQL và kết hợp các bảng. Trái ngược với NumPy, yêu cầu tất cả các mục trong một mảng phải cùng một loại, pandas cho phép mỗi cột có một loại riêng biệt (ví dụ: số nguyên, ngày tháng, số dấu phẩy động và chuỗi). Một công cụ có giá trị khác được cung cấp bởi pandas là khả năng nhập từ một loạt các định dạng tệp và cơ sở dữ liệu, như SQL, tệp Excel và tệp giá trị được phân tách bằng dấu phẩy (CSV). Đây là một ví dụ nhỏ về việc tạo DataFrame bằng từ điển:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>New York</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anna</td>\n",
       "      <td>Paris</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peter</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linda</td>\n",
       "      <td>London</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Location  Age\n",
       "0   John  New York   24\n",
       "1   Anna     Paris   13\n",
       "2  Peter    Berlin   53\n",
       "3  Linda    London   33"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# tạo một tập dữ liệu đơn giản về mọi người\n",
    "data = {'Name': [\"John\", \"Anna\", \"Peter\", \"Linda\"],\n",
    "        'Location' : [\"New York\", \"Paris\", \"Berlin\", \"London\"],\n",
    "        'Age' : [24, 13, 53, 33]\n",
    "       }\n",
    "\n",
    "data_pandas = pd.DataFrame(data)\n",
    "# IPython.display cho phép \"in đẹp\" các dataframe\n",
    "# trong Jupyter notebook\n",
    "display(data_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có một số cách để truy vấn bảng này. Ví dụ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peter</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linda</td>\n",
       "      <td>London</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name Location  Age\n",
       "2  Peter   Berlin   53\n",
       "3  Linda   London   33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chọn tất cả các hàng có cột tuổi lớn hơn 30\n",
    "display(data_pandas[data_pandas.Age > 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mglearn\n",
    "\n",
    "Cuốn sách này đi kèm với mã nguồn, bạn có thể tìm thấy trên GitHub. Mã nguồn đi kèm không chỉ bao gồm tất cả các ví dụ được trình bày trong cuốn sách này, mà còn cả thư viện **mglearn**. Đây là một thư viện các hàm tiện ích mà chúng tôi đã viết cho cuốn sách này, để chúng tôi không làm lộn xộn danh sách mã của mình với các chi tiết về vẽ đồ thị và tải dữ liệu. Nếu bạn quan tâm, bạn có thể tra cứu tất cả các hàm trong kho lưu trữ, nhưng các chi tiết của mô-đun mglearn không thực sự quan trọng đối với tài liệu trong cuốn sách này. Nếu bạn thấy một lời gọi đến mglearn trong mã, đó thường là một cách để tạo ra một bức ảnh đẹp một cách nhanh chóng, hoặc để lấy một số dữ liệu thú vị."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ad\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ad\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ad\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ad\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ad\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python 2 và Python 3\n",
    "Hiện tại có hai phiên bản chính của Python được sử dụng rộng rãi: Python 2 (chính xác hơn là 2.7) và Python 3 (với bản phát hành mới nhất là 3.5 tại thời điểm viết bài). Điều này đôi khi gây ra một số nhầm lẫn. Python 2 không còn được phát triển tích cực, nhưng vì Python 3 chứa các thay đổi lớn, mã Python 2 thường không chạy trên Python 3. Nếu bạn mới làm quen với Python, hoặc đang bắt đầu một dự án mới từ đầu, chúng tôi thực sự khuyên bạn nên sử dụng phiên bản mới nhất của Python 3 mà không có thay đổi. Nếu bạn có một cơ sở mã lớn mà bạn phụ thuộc vào được viết cho Python 2, bạn có thể tạm thời chưa nâng cấp. Tuy nhiên, bạn nên cố gắng chuyển sang Python 3 càng sớm càng tốt. Khi viết bất kỳ mã mới nào, phần lớn khá dễ dàng để viết mã chạy được trên cả Python 2 và Python 3. Nếu bạn không phải giao tiếp với phần mềm cũ, bạn chắc chắn nên sử dụng Python 3. Tất cả mã trong cuốn sách này được viết theo cách hoạt động cho cả hai phiên bản. Tuy nhiên, đầu ra chính xác có thể hơi khác một chút dưới Python 2.\n",
    "\n",
    "### Các phiên bản được sử dụng trong cuốn sách này\n",
    "Chúng tôi đang sử dụng các phiên bản sau của các thư viện đã đề cập trước đó trong cuốn sách này:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phiên bản Python: 3.13.2 (tags/v3.13.2:4f8bb39, Feb  4 2025, 15:23:48) [MSC v.1942 64 bit (AMD64)]\n",
      "Phiên bản pandas: 2.2.3\n",
      "Phiên bản matplotlib: 3.10.3\n",
      "Phiên bản NumPy: 2.2.4\n",
      "Phiên bản SciPy: 1.15.2\n",
      "Phiên bản IPython: 9.2.0\n",
      "Phiên bản scikit-learn: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Phiên bản Python: {}\".format(sys.version))\n",
    "\n",
    "import pandas as pd\n",
    "print(\"Phiên bản pandas: {}\".format(pd.__version__))\n",
    "\n",
    "import matplotlib\n",
    "print(\"Phiên bản matplotlib: {}\".format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np\n",
    "print(\"Phiên bản NumPy: {}\".format(np.__version__))\n",
    "\n",
    "import scipy as sp\n",
    "print(\"Phiên bản SciPy: {}\".format(sp.__version__))\n",
    "\n",
    "import IPython\n",
    "print(\"Phiên bản IPython: {}\".format(IPython.__version__))\n",
    "\n",
    "import sklearn\n",
    "print(\"Phiên bản scikit-learn: {}\".format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ứng dụng đầu tiên: Phân loại các loài hoa Iris\n",
    "\n",
    "Trong phần này, chúng ta sẽ đi qua một ứng dụng học máy đơn giản và tạo ra mô hình đầu tiên của mình. Trong quá trình này, chúng ta sẽ giới thiệu một số khái niệm và thuật ngữ cốt lõi.\n",
    "\n",
    "Giả sử một nhà thực vật học nghiệp dư quan tâm đến việc phân biệt các loài hoa iris mà cô ấy đã tìm thấy. Cô ấy đã thu thập một số phép đo liên quan đến mỗi bông hoa iris: chiều dài và chiều rộng của cánh hoa và chiều dài và chiều rộng của đài hoa, tất cả đều được đo bằng centimet.\n",
    "\n",
    "Cô ấy cũng có các phép đo của một số bông hoa iris đã được một nhà thực vật học chuyên gia xác định trước đó thuộc các loài **setosa**, **versicolor**, hoặc **virginica**. Đối với những phép đo này, cô ấy có thể chắc chắn về loài của mỗi bông hoa iris. Giả sử rằng đây là những loài duy nhất mà nhà thực vật học nghiệp dư của chúng ta sẽ gặp trong tự nhiên.\n",
    "\n",
    "Mục tiêu của chúng ta là xây dựng một mô hình học máy có thể học từ các phép đo của những bông hoa iris này có loài đã biết, để chúng ta có thể dự đoán loài cho một bông hoa iris mới."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vì chúng ta có các phép đo mà chúng ta biết loài iris chính xác, đây là một bài toán **học có giám sát**. Trong bài toán này, chúng ta muốn dự đoán một trong nhiều lựa chọn (loài iris). Đây là một ví dụ về bài toán **phân loại**. Các kết quả có thể có (các loài iris khác nhau) được gọi là **lớp**. Mỗi bông hoa iris trong tập dữ liệu thuộc về một trong ba lớp, vì vậy bài toán này là một bài toán phân loại ba lớp.\n",
    "\n",
    "Đầu ra mong muốn cho một điểm dữ liệu duy nhất (một bông hoa iris) là loài của bông hoa này. Đối với một điểm dữ liệu cụ thể, loài mà nó thuộc về được gọi là **nhãn** của nó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gặp gỡ dữ liệu\n",
    "Dữ liệu chúng ta sẽ sử dụng cho ví dụ này là **tập dữ liệu Iris**, một tập dữ liệu cổ điển trong học máy và thống kê. Nó được bao gồm trong scikit-learn trong mô-đun `datasets`. Chúng ta có thể tải nó bằng cách gọi hàm `load_iris`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đối tượng `iris` được trả về bởi `load_iris` là một đối tượng `Bunch`, rất giống với một từ điển. Nó chứa các khóa và giá trị:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các khóa của iris_dataset: \n",
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Các khóa của iris_dataset: \\n{}\".format(iris_dataset.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giá trị của khóa `DESCR` là một mô tả ngắn về tập dữ liệu. Chúng tôi hiển thị phần đầu của mô tả ở đây:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cơ sở dữ liệu cây Iris\n",
      "====================\n",
      "\n",
      "Ghi chú\n",
      "-----\n",
      "Đặc điểm tập dữ liệu:\n",
      "    :Số lượng mẫu: 150 (50 trong mỗi ba lớp)\n",
      "    :Số lượng thuộc tính: 4 số, dự đoán...\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['DESCR'][:193] + \"\\n...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giá trị của khóa `target_names` là một mảng các chuỗi, chứa các loài hoa mà chúng ta muốn dự đoán:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tên mục tiêu: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tên mục tiêu: {}\".format(iris_dataset['target_names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giá trị của `feature_names` là một danh sách các chuỗi, đưa ra mô tả của từng đặc trưng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tên đặc trưng: \n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tên đặc trưng: \\n{}\".format(iris_dataset['feature_names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu chính nó được chứa trong các trường `target` và `data`. `data` chứa các phép đo số của chiều dài đài hoa, chiều rộng đài hoa, chiều dài cánh hoa và chiều rộng cánh hoa trong một mảng NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loại dữ liệu: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Loại dữ liệu: {}\".format(type(iris_dataset['data'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các hàng trong mảng `data` tương ứng với các bông hoa, trong khi các cột đại diện cho bốn phép đo được thực hiện cho mỗi bông hoa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hình dạng dữ liệu: (150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Hình dạng dữ liệu: {}\".format(iris_dataset['data'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta thấy rằng mảng chứa các phép đo cho 150 bông hoa khác nhau. Hãy nhớ rằng các mục riêng lẻ được gọi là **mẫu** trong học máy, và các thuộc tính của chúng được gọi là **đặc trưng**. Hình dạng của mảng dữ liệu là số lượng mẫu nhân với số lượng đặc trưng. Đây là một quy ước trong scikit-learn, và dữ liệu của bạn sẽ luôn được giả định là có hình dạng này. Dưới đây là các giá trị đặc trưng cho năm mẫu đầu tiên:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Năm cột đầu tiên của dữ liệu:\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Năm cột đầu tiên của dữ liệu:\\n{}\".format(iris_dataset['data'][:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Từ dữ liệu này, chúng ta có thể thấy rằng tất cả năm bông hoa đầu tiên đều có chiều rộng cánh hoa là 0.2 cm và bông hoa đầu tiên có đài hoa dài nhất, ở mức 5.1 cm.\n",
    "\n",
    "Mảng `target` chứa loài của mỗi bông hoa đã được đo, cũng dưới dạng một mảng NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loại mục tiêu: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Loại mục tiêu: {}\".format(type(iris_dataset['target'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`target` là một mảng một chiều, với một mục cho mỗi bông hoa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hình dạng mục tiêu: (150,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Hình dạng mục tiêu: {}\".format(iris_dataset['target'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các loài được mã hóa thành các số nguyên từ 0 đến 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mục tiêu:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mục tiêu:\\n{}\".format(iris_dataset['target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ý nghĩa của các con số được cho bởi mảng `iris['target_names']`: 0 có nghĩa là setosa, 1 có nghĩa là versicolor, và 2 có nghĩa là virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đo lường thành công: Dữ liệu huấn luyện và dữ liệu kiểm tra\n",
    "\n",
    "Chúng ta muốn xây dựng một mô hình học máy từ dữ liệu này có thể dự đoán loài iris cho một tập hợp các phép đo mới. Nhưng trước khi chúng ta có thể áp dụng mô hình của mình cho các phép đo mới, chúng ta cần biết liệu nó có thực sự hoạt động hay không—tức là, liệu chúng ta có nên tin tưởng vào các dự đoán của nó hay không.\n",
    "\n",
    "Thật không may, chúng ta không thể sử dụng dữ liệu mà chúng ta đã sử dụng để xây dựng mô hình để đánh giá nó. Điều này là do mô hình của chúng ta luôn có thể chỉ cần ghi nhớ toàn bộ tập huấn luyện, và do đó sẽ luôn dự đoán đúng nhãn cho bất kỳ điểm nào trong tập huấn luyện. Việc “ghi nhớ” này không cho chúng ta biết liệu mô hình của chúng ta có tổng quát hóa tốt hay không (nói cách khác, liệu nó có hoạt động tốt trên dữ liệu mới hay không).\n",
    "\n",
    "Để đánh giá hiệu suất của mô hình, chúng ta cho nó xem dữ liệu mới (dữ liệu mà nó chưa từng thấy trước đây) mà chúng ta có nhãn. Điều này thường được thực hiện bằng cách chia dữ liệu có nhãn mà chúng ta đã thu thập (ở đây là 150 phép đo hoa của chúng ta) thành hai phần. Một phần của dữ liệu được sử dụng để xây dựng mô hình học máy của chúng ta, và được gọi là **dữ liệu huấn luyện** hoặc **tập huấn luyện**. Phần còn lại của dữ liệu sẽ được sử dụng để đánh giá mô hình hoạt động tốt như thế nào; phần này được gọi là **dữ liệu kiểm tra**, **tập kiểm tra**, hoặc **tập giữ lại**.\n",
    "\n",
    "scikit-learn chứa một hàm xáo trộn tập dữ liệu và chia nó cho bạn: hàm `train_test_split`. Hàm này trích xuất 75% các hàng trong dữ liệu làm tập huấn luyện, cùng với các nhãn tương ứng cho dữ liệu này. 25% còn lại của dữ liệu, cùng với các nhãn còn lại, được khai báo là tập kiểm tra. Việc quyết định bạn muốn đưa bao nhiêu dữ liệu vào tập huấn luyện và tập kiểm tra tương ứng là hơi tùy ý, nhưng việc sử dụng một tập kiểm tra chứa 25% dữ liệu là một quy tắc chung tốt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_dataset['data'], iris_dataset['target'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trước khi thực hiện việc chia, hàm `train_test_split` xáo trộn tập dữ liệu bằng cách sử dụng một bộ tạo số giả ngẫu nhiên. Nếu chúng ta chỉ lấy 25% dữ liệu cuối cùng làm tập kiểm tra, tất cả các điểm dữ liệu sẽ có nhãn 2, vì các điểm dữ liệu được sắp xếp theo nhãn (xem đầu ra cho `iris['target']` được hiển thị trước đó). Việc sử dụng một tập kiểm tra chỉ chứa một trong ba lớp sẽ không cho chúng ta biết nhiều về mức độ tổng quát hóa của mô hình, vì vậy chúng ta xáo trộn dữ liệu để đảm bảo tập kiểm tra chứa dữ liệu từ tất cả các lớp.\n",
    "\n",
    "Để đảm bảo rằng chúng ta sẽ nhận được cùng một đầu ra nếu chúng ta chạy cùng một hàm nhiều lần, chúng ta cung cấp cho bộ tạo số giả ngẫu nhiên một hạt giống cố định bằng cách sử dụng tham số `random_state`. Điều này sẽ làm cho kết quả trở nên xác định, vì vậy dòng này sẽ luôn có cùng một kết quả. Chúng ta sẽ luôn cố định `random_state` theo cách này khi sử dụng các thủ tục ngẫu nhiên trong cuốn sách này.\n",
    "\n",
    "Đầu ra của hàm `train_test_split` là `X_train`, `X_test`, `y_train` và `y_test`, tất cả đều là các mảng NumPy. `X_train` chứa 75% các hàng của tập dữ liệu, và `X_test` chứa 25% còn lại:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hình dạng X_train: (112, 4)\n",
      "Hình dạng y_train: (112,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Hình dạng X_train: {}\".format(X_train.shape))\n",
    "print(\"Hình dạng y_train: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hình dạng X_test: (38, 4)\n",
      "Hình dạng y_test: (38,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Hình dạng X_test: {}\".format(X_test.shape))\n",
    "print(\"Hình dạng y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Điều đầu tiên: Nhìn vào dữ liệu của bạn\n",
    "\n",
    "Trước khi xây dựng một mô hình học máy, thường là một ý tưởng tốt để kiểm tra dữ liệu, để xem liệu nhiệm vụ có thể dễ dàng giải quyết mà không cần học máy hay không, hoặc liệu thông tin mong muốn có thể không có trong dữ liệu hay không.\n",
    "\n",
    "Ngoài ra, việc kiểm tra dữ liệu của bạn là một cách tốt để tìm ra những điểm bất thường và đặc biệt. Ví dụ, có thể một số bông hoa iris của bạn được đo bằng inch chứ không phải centimet. Trong thế giới thực, sự không nhất quán trong dữ liệu và các phép đo bất ngờ rất phổ biến.\n",
    "\n",
    "Một trong những cách tốt nhất để kiểm tra dữ liệu là trực quan hóa nó. Một cách để làm điều này là sử dụng một **biểu đồ phân tán**. Một biểu đồ phân tán của dữ liệu đặt một đặc trưng dọc theo trục x và một đặc trưng khác dọc theo trục y, và vẽ một dấu chấm cho mỗi điểm dữ liệu. Thật không may, màn hình máy tính chỉ có hai chiều, cho phép chúng ta chỉ vẽ được hai (hoặc có thể là ba) đặc trưng tại một thời điểm. Rất khó để vẽ các tập dữ liệu có nhiều hơn ba đặc trưng theo cách này. Một cách giải quyết vấn đề này là thực hiện một **biểu đồ cặp**, nó xem xét tất cả các cặp đặc trưng có thể có. Nếu bạn có một số lượng nhỏ các đặc trưng, chẳng hạn như bốn đặc trưng chúng ta có ở đây, điều này khá hợp lý. Tuy nhiên, bạn nên ghi nhớ rằng một biểu đồ cặp không hiển thị sự tương tác của tất cả các đặc trưng cùng một lúc, vì vậy một số khía cạnh thú vị của dữ liệu có thể không được tiết lộ khi trực quan hóa nó theo cách này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mglearn\n",
    "\n",
    "# tạo dataframe từ dữ liệu trong X_train\n",
    "# gán nhãn cho các cột bằng các chuỗi trong iris_dataset.feature_names\n",
    "iris_dataframe = pd.DataFrame(X_train, columns=iris_dataset.feature_names)\n",
    "# tạo một ma trận phân tán từ dataframe, tô màu theo y_train\n",
    "grr = pd.plotting.scatter_matrix(iris_dataframe, c=y_train, figsize=(15, 15), \n",
    "                           marker='o', hist_kwds={'bins': 20}, s=60, \n",
    "                           alpha=.8, cmap=mglearn.cm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Từ các biểu đồ, chúng ta có thể thấy rằng ba lớp dường như được phân tách tương đối tốt bằng cách sử dụng các phép đo đài hoa và cánh hoa. Điều này có nghĩa là một mô hình học máy có khả năng sẽ có thể học cách tách chúng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xây dựng mô hình đầu tiên của bạn: k-Hàng xóm gần nhất\n",
    "Bây giờ chúng ta có thể bắt đầu xây dựng mô hình học máy thực tế. Có nhiều thuật toán phân loại trong scikit-learn mà chúng ta có thể sử dụng. Ở đây chúng ta sẽ sử dụng bộ phân loại **k-hàng xóm gần nhất**, rất dễ hiểu. Việc xây dựng mô hình này chỉ bao gồm việc lưu trữ tập huấn luyện. Để đưa ra dự đoán cho một điểm dữ liệu mới, thuật toán sẽ tìm điểm trong tập huấn luyện gần nhất với điểm mới. Sau đó, nó gán nhãn của điểm huấn luyện này cho điểm dữ liệu mới.\n",
    "\n",
    "Ký tự k trong k-hàng xóm gần nhất biểu thị rằng thay vì chỉ sử dụng hàng xóm gần nhất với điểm dữ liệu mới, chúng ta có thể xem xét một số lượng cố định k hàng xóm bất kỳ trong quá trình huấn luyện (ví dụ: ba hoặc năm hàng xóm gần nhất). Sau đó, chúng ta có thể đưa ra dự đoán bằng cách sử dụng lớp đa số trong số các hàng xóm này. Chúng ta sẽ đi sâu hơn vào chi tiết này trong Chương 2; bây giờ, chúng ta sẽ chỉ sử dụng một hàng xóm duy nhất.\n",
    "\n",
    "Tất cả các mô hình học máy trong scikit-learn được triển khai trong các lớp riêng của chúng, được gọi là các lớp `Estimator`. Thuật toán phân loại k-hàng xóm gần nhất được triển khai trong lớp `KNeighborsClassifier` trong mô-đun `neighbors`. Trước khi chúng ta có thể sử dụng mô hình, chúng ta cần khởi tạo lớp thành một đối tượng. Đây là lúc chúng ta sẽ thiết lập bất kỳ tham số nào của mô hình. Tham số quan trọng nhất của `KNeighborsClassifier` là số lượng hàng xóm, mà chúng ta sẽ đặt thành 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đối tượng `knn` đóng gói thuật toán sẽ được sử dụng để xây dựng mô hình từ dữ liệu huấn luyện, cũng như thuật toán để đưa ra dự đoán trên dữ liệu mới. Nó cũng sẽ giữ thông tin mà thuật toán đã trích xuất từ dữ liệu huấn luyện. Trong trường hợp của `KNeighborsClassifier`, nó sẽ chỉ lưu trữ tập huấn luyện.\n",
    "\n",
    "Để xây dựng mô hình trên tập huấn luyện, chúng ta gọi phương thức `fit` của đối tượng `knn`, nó nhận các đối số là mảng NumPy `X_train` chứa dữ liệu huấn luyện và mảng NumPy `y_train` của các nhãn huấn luyện tương ứng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phương thức `fit` trả về chính đối tượng `knn` (và sửa đổi nó tại chỗ), vì vậy chúng ta nhận được một biểu diễn chuỗi của bộ phân loại của mình. Biểu diễn này cho chúng ta thấy những tham số nào đã được sử dụng để tạo mô hình. Hầu hết chúng đều là các giá trị mặc định, nhưng bạn cũng có thể tìm thấy `n_neighbors=1`, là tham số mà chúng ta đã truyền vào. Hầu hết các mô hình trong scikit-learn đều có nhiều tham số, nhưng phần lớn chúng là các tối ưu hóa tốc độ hoặc cho các trường hợp sử dụng rất đặc biệt. Bạn không cần phải lo lắng về các tham số khác được hiển thị trong biểu diễn này. Việc in một mô hình scikit-learn có thể tạo ra các chuỗi rất dài, nhưng đừng bị chúng làm cho sợ hãi. Chúng ta sẽ đề cập đến tất cả các tham số quan trọng trong Chương 2. Trong phần còn lại của cuốn sách này, chúng ta sẽ không hiển thị đầu ra của `fit` vì nó không chứa bất kỳ thông tin mới nào."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đưa ra dự đoán\n",
    "Bây giờ chúng ta có thể đưa ra dự đoán bằng mô hình này trên dữ liệu mới mà chúng ta có thể không biết nhãn chính xác. Hãy tưởng tượng chúng ta tìm thấy một bông hoa iris trong tự nhiên có chiều dài đài hoa là 5 cm, chiều rộng đài hoa là 2.9 cm, chiều dài cánh hoa là 1 cm và chiều rộng cánh hoa là 0.2 cm. Loài iris này sẽ là gì? Chúng ta có thể đưa dữ liệu này vào một mảng NumPy, một lần nữa bằng cách tính toán hình dạng—tức là, số lượng mẫu (1) nhân với số lượng đặc trưng (4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hình dạng X_new: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
    "print(\"Hình dạng X_new: {}\".format(X_new.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý rằng chúng ta đã biến các phép đo của một bông hoa duy nhất này thành một hàng trong một mảng NumPy hai chiều, vì scikit-learn luôn mong đợi các mảng hai chiều cho dữ liệu.\n",
    "\n",
    "Để đưa ra dự đoán, chúng ta gọi phương thức `predict` của đối tượng `knn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dự đoán: [0]\n",
      "Tên mục tiêu dự đoán: ['setosa']\n"
     ]
    }
   ],
   "source": [
    "prediction = knn.predict(X_new)\n",
    "print(\"Dự đoán: {}\".format(prediction))\n",
    "print(\"Tên mục tiêu dự đoán: {}\".format(\n",
    "    iris_dataset['target_names'][prediction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mô hình của chúng ta dự đoán rằng bông hoa iris mới này thuộc về lớp 0, có nghĩa là loài của nó là setosa. Nhưng làm thế nào để chúng ta biết liệu chúng ta có thể tin tưởng vào mô hình của mình hay không? Chúng ta không biết loài chính xác của mẫu này, đó là toàn bộ mục đích của việc xây dựng mô hình!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đánh giá mô hình\n",
    "Đây là lúc tập kiểm tra mà chúng ta đã tạo trước đó phát huy tác dụng. Dữ liệu này không được sử dụng để xây dựng mô hình, nhưng chúng ta biết loài chính xác của mỗi bông hoa iris trong tập kiểm tra.\n",
    "\n",
    "Do đó, chúng ta có thể đưa ra dự đoán cho mỗi bông hoa iris trong dữ liệu kiểm tra và so sánh nó với nhãn của nó (loài đã biết). Chúng ta có thể đo lường mô hình hoạt động tốt như thế nào bằng cách tính toán **độ chính xác**, là tỷ lệ phần trăm các bông hoa được dự đoán đúng loài:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dự đoán tập kiểm tra:\n",
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(\"Dự đoán tập kiểm tra:\\n {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Điểm tập kiểm tra: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Điểm tập kiểm tra: {:.2f}\".format(np.mean(y_pred == y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta cũng có thể sử dụng phương thức `score` của đối tượng `knn`, nó sẽ tính toán độ chính xác của tập kiểm tra cho chúng ta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Điểm tập kiểm tra: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Điểm tập kiểm tra: {:.2f}\".format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đối với mô hình này, độ chính xác của tập kiểm tra là khoảng 0.97, có nghĩa là chúng ta đã đưa ra dự đoán đúng cho 97% số hoa iris trong tập kiểm tra. Dưới một số giả định toán học, điều này có nghĩa là chúng ta có thể mong đợi mô hình của mình sẽ đúng 97% thời gian đối với các bông hoa iris mới. Đối với ứng dụng của nhà thực vật học nghiệp dư của chúng ta, mức độ chính xác cao này có nghĩa là mô hình của chúng ta có thể đủ đáng tin cậy để sử dụng. Trong các chương sau, chúng ta sẽ thảo luận về cách chúng ta có thể cải thiện hiệu suất, và những lưu ý cần có khi tinh chỉnh một mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tóm tắt và Triển vọng\n",
    "Hãy tóm tắt những gì chúng ta đã học được trong chương này. Chúng ta bắt đầu với một giới thiệu ngắn gọn về học máy và các ứng dụng của nó, sau đó thảo luận về sự khác biệt giữa học có giám sát và không giám sát và đưa ra một cái nhìn tổng quan về các công cụ chúng ta sẽ sử dụng trong cuốn sách này. Sau đó, chúng ta đã xây dựng nhiệm vụ dự đoán loài của một bông hoa iris cụ thể bằng cách sử dụng các phép đo vật lý của bông hoa. Chúng ta đã sử dụng một tập dữ liệu các phép đo được một chuyên gia chú thích với loài chính xác để xây dựng mô hình của mình, biến đây thành một nhiệm vụ học có giám sát. Có ba loài có thể có, setosa, versicolor, hoặc virginica, đã biến nhiệm vụ này thành một bài toán phân loại ba lớp. Các loài có thể có được gọi là lớp trong bài toán phân loại, và loài của một bông hoa iris duy nhất được gọi là nhãn của nó.\n",
    "\n",
    "Tập dữ liệu Iris bao gồm hai mảng NumPy: một chứa dữ liệu, được gọi là X trong scikit-learn, và một chứa các đầu ra chính xác hoặc mong muốn, được gọi là y. Mảng X là một mảng hai chiều các đặc trưng, với một hàng cho mỗi điểm dữ liệu và một cột cho mỗi đặc trưng. Mảng y là một mảng một chiều, ở đây chứa một nhãn lớp, một số nguyên từ 0 đến 2, cho mỗi mẫu.\n",
    "\n",
    "Chúng ta đã chia tập dữ liệu của mình thành một tập huấn luyện, để xây dựng mô hình của chúng ta, và một tập kiểm tra, để đánh giá mức độ tổng quát hóa của mô hình của chúng ta đối với dữ liệu mới, chưa từng thấy trước đây.\n",
    "\n",
    "Chúng ta đã chọn thuật toán phân loại k-hàng xóm gần nhất, nó đưa ra dự đoán cho một điểm dữ liệu mới bằng cách xem xét (các) hàng xóm gần nhất của nó trong tập huấn luyện. Điều này được triển khai trong lớp `KNeighborsClassifier`, nó chứa thuật toán xây dựng mô hình cũng như thuật toán đưa ra dự đoán bằng mô hình. Chúng ta đã khởi tạo lớp, thiết lập các tham số. Sau đó, chúng ta xây dựng mô hình bằng cách gọi phương thức `fit`, truyền dữ liệu huấn luyện (`X_train`) và đầu ra huấn luyện (`y_train`) làm tham số. Chúng ta đã đánh giá mô hình bằng phương thức `score`, nó tính toán độ chính xác của mô hình. Chúng ta đã áp dụng phương thức score cho dữ liệu tập kiểm tra và nhãn tập kiểm tra và thấy rằng mô hình của chúng ta có độ chính xác khoảng 97%, có nghĩa là nó đúng 97% thời gian trên tập kiểm tra.\n",
    "\n",
    "Điều này đã cho chúng ta sự tự tin để áp dụng mô hình cho dữ liệu mới (trong ví dụ của chúng ta, các phép đo hoa mới) và tin tưởng rằng mô hình sẽ đúng khoảng 97% thời gian.\n",
    "\n",
    "Đây là bản tóm tắt mã cần thiết cho toàn bộ quy trình huấn luyện và đánh giá:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Điểm tập kiểm tra: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_dataset['data'], iris_dataset['target'], random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Điểm tập kiểm tra: {:.2f}\".format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đoạn mã này chứa mã cốt lõi để áp dụng bất kỳ thuật toán học máy nào bằng scikit-learn. Các phương thức `fit`, `predict` và `score` là giao diện chung cho các mô hình có giám sát trong scikit-learn, và với các khái niệm được giới thiệu trong chương này, bạn có thể áp dụng các mô hình này cho nhiều nhiệm vụ học máy. Trong chương tiếp theo, chúng ta sẽ đi sâu hơn về các loại mô hình có giám sát khác nhau trong scikit-learn và cách áp dụng chúng một cách thành công."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

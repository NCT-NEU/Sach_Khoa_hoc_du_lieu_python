{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecb82f2-c638-4c57-84ea-b988a07746bb",
   "metadata": {},
   "source": [
    "![](../docs/banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac493f0-95ad-488e-9206-db1d82803190",
   "metadata": {},
   "source": [
    "# Các khái niệm cơ bản trong khoa học dữ liệu\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e5475-c32b-4247-b857-c70d52c51230",
   "metadata": {},
   "source": [
    "Chương sách này sẽ giới thiệu một cách hệ thống các khái niệm nền tảng trong khoa học dữ liệu.\n",
    "Nội dung chương bắt đầu từ xác lập định nghĩa dữ liệu trong các bối cảnh khác nhau như dữ liệu định lượng, dữ liệu định tính cho đến dữ liệu có cấu trúc, dữ liệu phi cấu trúc.\n",
    "Tiếp theo, chương trình bày tổng quan về các nền tảng công nghệ đóng vai trò cốt lõi trong việc thu thập, lưu trữ, xử lý và phân tích dữ liệu, bao gồm hệ quản trị cơ sở dữ liệu, công nghệ lưu trữ phân tán, điện toán đám mây và các ngôn ngữ lập trình phổ biến trong lĩnh vực này.\n",
    "\n",
    "Phần tiếp theo của chương sẽ làm rõ hệ sinh thái nghề nghiệp trong khoa học dữ liệu – một lĩnh vực có tính liên ngành cao và đòi hỏi sự cộng tác của nhiều vai trò chuyên biệt.\n",
    "Các vai trò như nhà phân tích dữ liệu (Data Analyst), kỹ sư dữ liệu (Data Engineer), nhà khoa học dữ liệu (Data Scientist), ..., sẽ được giới thiệu và phân biệt rõ ràng về chức năng, kỹ năng cốt lõi cũng như vị trí trong quy trình phân tích dữ liệu toàn diện."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfe8aeb-5e6d-492f-9f9d-3c344a6cde9f",
   "metadata": {},
   "source": [
    "## Giới thiệu chung\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3379fe-b2bc-4bd6-88f8-08a1dc4001f5",
   "metadata": {},
   "source": [
    "### Khái niệm về Khoa học dữ liệu\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc02a79c-d8f7-462d-94f0-ca71f292d714",
   "metadata": {},
   "source": [
    "Khoa học dữ liệu (Data Science) là một lĩnh vực liên ngành, kết hợp chặt chẽ giữa ba trụ cột chính: toán học và thống kê, khoa học máy tính, và kiến thức chuyên sâu về lĩnh vực ứng dụng (domain knowledge).\n",
    "Sự giao thoa giữa ba thành phần này tạo nên nền tảng lý thuyết và thực tiễn vững chắc để khai thác giá trị từ dữ liệu.\n",
    "```{figure} ../docs/intro1.png\n",
    ":width: 450px\n",
    ":align: center\n",
    "Khoa học dữ liệu là kết hợp giữa Toán - thống kê, Khoa học máy tính, và Kiến thức chuyên môn\n",
    "```\n",
    "\n",
    "Một quy trình ứng dụng Khoa học dữ liệu để giải quyết một vấn đề trong các tổ chức thường bao gồm các bước như sau\n",
    "\n",
    "```{figure} ../docs/intro2.png\n",
    ":width: 600px\n",
    ":align: center\n",
    "Các bước trong một quy trình ứng dụng Khoa học dữ liệu để giải quyết vấn đề\n",
    "```\n",
    "\n",
    "-   **Nhập liệu** là quá trình tìm kiếm và thu thập dữ liệu từ các nguồn khác nhau nhằm phục vụ cho mục đích ra quyết định.\n",
    "    Có những dự án làm việc trực tiếp trên dữ liệu có sẵn và đã được thiết kế sẵn sàng cho mục tiêu phân tích, nhưng cũng có những dự án mà quá trình nhập liệu lại chiếm phần lớn thời gian và quyết định sự thành công hay thất bại của dự án.\n",
    "\n",
    "-   **Sắp xếp** hay tổ chức dữ liệu, hay còn được gọi là tiền xử lý dữ liệu, là các bước biến dữ liệu từ dạng thô thành dữ liệu theo đúng như định dạng mong muốn.\n",
    "\n",
    "-   **Biến đổi** dữ liệu là quá trình tính toán trên các biến hoặc các quan sát của dữ liệu để dữ liệu có thể đưa vào các công cụ trực quan hoặc các mô hình phân tích.\n",
    "\n",
    "-   **Trực quan** dữ liệu là là quá trình biến dữ liệu dạng số, bảng biểu hoặc văn bản thành các biểu diễn hình ảnh như biểu đồ, đồ thị, bản đồ, sơ đồ... nhằm giúp người xem hiểu, phân tích và rút ra thông tin một cách dễ dàng và trực quan hơn.\n",
    "\n",
    "-   **Xây dựng mô hình** là quá trình tính toán và đánh giá mối liên hệ giữa các biến trong dữ liệu đến các biến mục tiêu, là đầu ra của toàn bộ quá trình.\n",
    "    Mô hình thường được xây dựng với một trong hai mục đích: xem xét sự tác động của một biến giải thích đến các biến mục tiêu, hoặc dự đoán giá trị của các biến mục tiêu dựa trên các giá trị sẵn có của biến giải thích.\n",
    "\n",
    "Mô hình trên dữ liệu được xây dựng dựa trên những nguyên lý của toán học và xác suất thống kê.\n",
    "Dữ liệu được sử dụng để xây dựng mô hình có thể là các dữ liệu nhỏ với một vài cột (biến) và vài chục dòng (quan sát), nhưng cũng có thể là các dữ liệu lớn với hàng nghìn cột và hàng triệu quan sát.\n",
    "Dữ liệu thậm chí không có dạng bảng biểu như chúng ta gặp hàng ngày mà có thể là các hình ảnh, các văn bản, giọng nói, dạng đồ thị,...\n",
    "Để xử lý các bộ dữ liệu phức tạp, có kích thước khổng lồ, hay các dữ liệu không có cấu trúc bảng thông thường, người xử lý dữ liệu cần có kiến thức về lập trình và khoa học máy tính để thực hiện các phép tính toán dữ liệu trên máy tính điện tử.\n",
    "\n",
    "Những ứng dụng của KHDL có thể thuộc về bất kỳ lĩnh vực nào như kinh doanh, y học, vật lý, thiên văn, quản lý nhà nước, chính sách công, v.v.\n",
    "nên đòi hỏi người xây dựng mô hình cũng cần có kiến thức chuyên môn trong lĩnh vực tương ứng để không bị sai định hướng trong quá trình làm việc với dữ liệu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a3cfb2-8d7d-4c5a-997e-fb6df017e36e",
   "metadata": {},
   "source": [
    "### Khoa học dữ liệu trong Kinh tế và Kinh doanh\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa817f-5989-41c0-8a09-41b17ad7cd55",
   "metadata": {},
   "source": [
    "**Khoa học dữ liệu trong kinh tế và kinh doanh** có những đặc thù khác biệt so với khoa học dữ liệu trong các lĩnh vực như kỹ thuật, y sinh học, hay khoa học tự nhiên.\n",
    "Sự khác biệt này xuất phát từ bản chất của dữ liệu, mục tiêu phân tích, và bối cảnh ra quyết định.\n",
    "\n",
    "-   Trước hết, trong các ứng dụng kinh tế và kinh doanh, dữ liệu thường có nguồn gốc hành vi của con người, phản ánh các quá trình ra quyết định của con người như tiêu dùng, đầu tư, định giá, hoặc quản trị rủi ro.\n",
    "    Dữ liệu trong lĩnh vực này thường không độc lập mà chịu ảnh hưởng của kỳ vọng, thông tin bất cân xứng và các yếu tố kinh tế vĩ mô, điều này đòi hỏi cách tiếp cận khác biệt so với các lĩnh vực dữ liệu vật lý thuần túy.\n",
    "\n",
    "-   Thứ hai, các mô hình được sử dụng trong kinh tế và kinh doanh thường cần giải thích được về mặt ý nghĩa kinh tế học hoặc ý nghĩa trong quản trị doanh nghiệp, nhằm phục vụ quá trình ra quyết định của con người hoặc tổ chức.\n",
    "    Do đó, khoa học dữ liệu trong lĩnh vực này không chỉ tập trung vào độ chính xác dự đoán, mà còn phải đảm bảo tính minh bạch, khả năng giải thích nhân quả, và sự phù hợp với lý thuyết nền tảng.\n",
    "\n",
    "-   Cuối cùng, mục tiêu của khoa học dữ liệu trong kinh tế – kinh doanh thường liên quan đến tối ưu hóa lợi nhuận, hiệu quả vận hành, hoặc ra quyết định chiến lược, chứ không chỉ dừng lại ở mô hình hóa hoặc phát hiện các giá trị của dữ liệu.\n",
    "    Điều này khiến khoa học dữ liệu trong lĩnh vực này thường kết hợp chặt chẽ với các mô hình kinh tế lượng, tài chính định lượng, và các công cụ ra quyết định định lượng khác."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675cefe8-4b20-4721-b915-c978ac6fd687",
   "metadata": {
    "language": "r"
   },
   "source": [
    "### Sự phát triển của hệ sinh thái dữ liệu hiện đại\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cdb483-3778-4295-9428-02fc8799b76f",
   "metadata": {},
   "source": [
    "Sự phát triển không ngừng của tốc độ xử lý dữ liệu, băng thông mạng, cùng với sự xuất hiện liên tục của các công cụ tạo lập và chia sẻ dữ liệu đã tạo ra một chu trình tăng trưởng dữ liệu liên tục và khép kín.\n",
    "Trong bối cảnh đó, hệ sinh thái dữ liệu hiện đại được cấu thành từ mạng lưới phức hợp gồm các nguồn dữ liệu đa dạng, công cụ phân tích chuyên biệt, các hạ tầng công nghệ có khả năng lưu trữ, xử lý và phân phối dữ liệu.\n",
    "\n",
    "Dữ liệu ngày nay tồn tại dưới nhiều định dạng khác nhau, từ văn bản, hình ảnh, video, dữ liệu cảm biến, tương tác người dùng, đến dòng sự kiện theo thời gian thực.\n",
    "Việc tích hợp và trích xuất dữ liệu từ các nguồn dữ liệu đa dạng thường là bước đầu tiên trong quy trình phân tích dữ liệu.\n",
    "Tiếp theo, dữ liệu cần được làm sạch, chuẩn hóa và tối ưu hóa để phù hợp với các quy chuẩn nội bộ. Trong nhiều trường hợp, dữ liệu được sử dụng cần phải tuân theo các quy định pháp lý, đặc biệt trong trường hợp dữ liệu cá nhân hoặc dữ liệu nhạy cảm.\n",
    "Sau cùng, các ứng dụng, các chuyên viên phân tích, các chuyên gia xây dựng mô hình sẽ truy xuất dữ liệu từ các cơ sở dữ liệu để phục vụ các mục tiêu nghiệp vụ cụ thể.\n",
    "\n",
    "Trong hệ sinh thái này, một số công nghệ đang định hình xu thế mới bao gồm: điện toán đám mây, các mô hình học máy, và các nền tảng phân tích dữ liệu lớn (big data).\n",
    "Nhờ có nền tảng đám mây, các tổ chức ngày nay có thể dễ dàng tiếp cận với khả năng lưu trữ gần như vô hạn, tính toán hiệu năng cao, và bộ công cụ học máy hiện đại.\n",
    "Các nhà khoa học dữ liệu có thể huấn luyện mô hình dự đoán trên khối dữ liệu lịch sử khổng lồ, vượt qua giới hạn của các công cụ phân tích truyền thống, để tạo ra tri thức mới và tăng cường khả năng ra quyết định dựa trên dữ liệu.\n",
    "\n",
    "Việc khai thác hiệu quả giá trị từ dữ liệu đòi hỏi một hệ sinh thái nhân lực đa dạng với nhiều vai trò chuyên biệt:\n",
    "\n",
    "-   Kỹ sư dữ liệu (data engineer) là người xây dựng và duy trì kiến trúc dữ liệu.\n",
    "    Họ đảm nhiệm việc trích xuất, tích hợp, và tổ chức dữ liệu từ nhiều nguồn, đảm bảo dữ liệu sẵn sàng cho các ứng dụng và phân tích.\n",
    "\n",
    "-   Chuyên viên phân tích dữ liệu (data analyst) là người diễn giải dữ liệu thành thông tin hữu ích.\n",
    "    Họ làm sạch, trực quan hóa dữ liệu, áp dụng các phương pháp thống kê để khám phá mối quan hệ và xu hướng, từ đó hỗ trợ ra quyết định.\n",
    "\n",
    "-   Nhà khoa học dữ liệu (data scientist) là người xây dựng các mô hình dự đoán dựa trên học máy hoặc học sâu.\n",
    "    Họ kết hợp kiến thức về toán, thống kê, lập trình và kiến thức chuyên ngành để đưa ra các giải pháp phân tích tiên tiến.\n",
    "\n",
    "-   Chuyên viên phân tích nghiệp vụ (business analyst) sử dụng đầu ra từ các vai trò trên để đánh giá tác động đến tổ chức, đưa ra khuyến nghị chiến lược hoặc cải thiện hiệu quả hoạt động, tập trung vào cả yếu tố nội tại lẫn ảnh hưởng từ môi trường bên ngoài.\n",
    "\n",
    "Tóm lại, kỹ sư dữ liệu tạo ra nền tảng dữ liệu có thể sử dụng được, nhà phân tích khai thác dữ liệu để rút ra tri thức, nhà khoa học dữ liệu dự đoán tương lai dựa vào quá khứ, và các nhà phân tích nghiệp vụ sử dụng những tri thức này để ra quyết định có giá trị thực tiễn.\n",
    "Trong thực tế, sự dịch chuyển giữa các vai trò trong hệ sinh thái dữ liệu là phổ biến và được thúc đẩy bởi quá trình tích lũy kỹ năng liên ngành. Vai trò cụ thể của các nhân lực trong lĩnh vực khoa học dữ liệu sẽ được thảo luận trong phần sau của chương.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a69fd5-819b-4904-95a8-2056eb96109c",
   "metadata": {},
   "source": [
    "### Phân tích dữ liệu hay khoa học dữ liệu\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f056fe29-4cfc-4625-aaf1-bc83eec18e39",
   "metadata": {},
   "source": [
    "**Khoa học dữ liệu** là một lĩnh vực liên ngành rộng lớn không chỉ bao gồm phân tích mà còn liên quan đến xây dựng mô hình dự đoán, phát triển thuật toán và tối ưu hóa, tự động hóa quy trình ra quyết định dựa trên dữ liệu.\n",
    "**Phân tích dữ liệu** là một thành phần thiết yếu trong khoa học dữ liệu, nhưng không bao gồm các kỹ thuật xây dựng mô hình phức tạp, tự động hóa mô hình, ứng dụng trí tuệ nhân tạo, và khai thác dữ liệu ở quy mô lớn.\n",
    "\n",
    "Mục tiêu cốt lõi của phân tích dữ liệu là phát hiện các giá trị trong dữ liệu, các mối liên hệ giữa các biến trong dữ liệu, từ đó hình thành các hiểu biết và định hướng hành động trong tương lai.\n",
    "Việc áp dụng phân tích dữ liệu không chỉ giúp các tổ chức hiểu rõ hơn về hiệu suất trong quá khứ mà còn cung cấp cơ sở để đánh giá, lựa chọn và tối ưu hóa các chiến lược kinh doanh.\n",
    "\n",
    "Có bốn hình thức phân tích dữ liệu chính:\n",
    "\n",
    "-   **Phân tích mô tả** (descriptive analytics): tóm lược và trình bày các sự kiện đã xảy ra, thường được sử dụng để phản ánh các chỉ số hiệu quả trong quá khứ.\n",
    "\n",
    "-   **Phân tích chẩn đoán** (diagnostic analytics): làm rõ nguyên nhân đằng sau các hiện tượng được phát hiện ở bước mô tả, thông qua truy vết và phân tích các yếu tố ảnh hưởng.\n",
    "\n",
    "-   **Phân tích dự đoán** (predictive analytics): sử dụng dữ liệu quá khứ và mô hình thống kê để dự báo xu hướng hoặc kết quả tiềm năng trong tương lai, với bản chất mang tính xác suất.\n",
    "\n",
    "-   **Phân tích đề xuất** (prescriptive analytics): gợi ý hành động tối ưu dựa trên phân tích các kết quả khả dĩ và xác suất xảy ra của chúng, thường ứng dụng trong các hệ thống ra quyết định tự động.\n",
    "\n",
    "Quy trình phân tích dữ liệu bao thường gồm các bước: xác định vấn đề và mục tiêu phân tích; xác lập tiêu chí đo lường; thu thập và làm sạch dữ liệu; phân tích và khai phá dữ liệu; diễn giải kết quả; và trình bày phát hiện một cách hiệu quả, thường thông qua báo cáo, biểu đồ, dashboard hoặc trình bày tương tác.\n",
    "\n",
    "Hay khái niệm có thể gây nhầm lẫn với bạn đọc là **data analysis** và **data analytics**.\n",
    "Thực tế thì\n",
    "\n",
    "-   **Analysis**, hay phân tích nói chung, được hiểu là sự kiểm tra một cách chi tiết cấu trúc của một đối tượng – có thể không liên quan đến dữ liệu định lượng, ví dụ như phân tích kinh doanh hay phân tích tâm lý.\n",
    "\n",
    "-   **Analytics**, hay phân tích dựa trên dữ liệu, hàm ý việc kiểm tra có áp dụng các kỹ thuật tính toán hoặc thống kê có hệ thống lên dữ liệu số nhằm suy luận và ra quyết định.\n",
    "\n",
    "Tuy nhiên, trong nhiều bối cảnh thực tiễn và cả trong khuôn khổ cuốn sách này, hai thuật ngữ vẫn được dùng hoán đổi, đặc biệt khi đề cập đến các kỹ thuật xử lý dữ liệu nhằm hỗ trợ ra quyết định.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f7a522-364c-49e4-b6d4-0e0a6cb6b2e2",
   "metadata": {},
   "source": [
    "## Dữ liệu là gì ?\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f57afa4-fb25-4cc2-a0ae-85b9d1282a69",
   "metadata": {},
   "source": [
    "Dữ liệu là thông tin chưa được xử lý, tồn tại ở dạng thô và cần được tổ chức lại để trở nên có ý nghĩa.\n",
    "Nói cách khác, dữ liệu là tập hợp của các sự kiện, quan sát, nhận thức, con số, ký tự, biểu tượng hoặc hình ảnh, tất cả đều có thể được giải thích để rút ra thông tin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cf91cb-0378-44c8-9c1d-027728759d0d",
   "metadata": {},
   "source": [
    "### Phân loại dữ liệu\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b3c9cb-6cf9-4167-94b1-a5aead2751ed",
   "metadata": {},
   "source": [
    "Một trong những cách phổ biến để phân loại dữ liệu là dựa trên cấu trúc.\n",
    "Theo tiêu chí này, dữ liệu được chia thành ba loại chính: dữ liệu có cấu trúc (structured), dữ liệu kiểu bán cấu trúc (semi-structured), dữ liệu phi cấu trúc (unstructured).\n",
    "\n",
    "**Dữ liệu có cấu trúc** là loại dữ liệu có định dạng rõ ràng, tuân theo một mô hình dữ liệu được xác định trước và thường được lưu trữ trong các hệ quản trị cơ sở dữ liệu dạng quan hệ (relational databases).\n",
    "Dữ liệu này có thể được biểu diễn dưới dạng bảng với các hàng và cột, cho phép xử lý bằng các công cụ và kỹ thuật phân tích dữ liệu truyền thống.\n",
    "\n",
    "Các nguồn phổ biến lưu trữ và cung cấp dữ liệu có cấu trúc bao gồm:\n",
    "\n",
    "-   Cơ sở dữ liệu quan hệ (SQL Databases)\n",
    "\n",
    "-   Bảng tính điện tử như Excel hoặc Google Sheets\n",
    "\n",
    "**Dữ liệu bán cấu trúc** là loại dữ liệu có một số đặc điểm tổ chức, nhưng không tuân theo một lược đồ dữ liệu cố định như dữ liệu có cấu trúc.\n",
    "Dữ liệu bán cấu trúc không thể biểu diễn một cách chặt chẽ bằng hàng và cột trong cơ sở dữ liệu.\n",
    "Thay vào đó, nó chứa các thẻ hoặc thuộc tính dùng để nhóm thông tin và sắp xếp theo cấu trúc phân cấp.\n",
    "\n",
    "Một số nguồn dữ liệu bán cấu trúc điển hình:\n",
    "\n",
    "-   Email\n",
    "\n",
    "-   Tài liệu XML hoặc các ngôn ngữ đánh dấu khác\n",
    "\n",
    "Các định dạng như XML và JSON là phương tiện phổ biến để lưu trữ và trao đổi dữ liệu bán cấu trúc nhờ khả năng định nghĩa các thẻ và thuộc tính theo yêu cầu người dùng.\n",
    "\n",
    "**Dữ liệu phi cấu trúc** là loại dữ liệu không có định dạng cụ thể hoặc không tuân theo bất kỳ quy tắc cú pháp nào rõ ràng.\n",
    "Do đó, loại dữ liệu này không thể lưu trữ hiệu quả trong cơ sở dữ liệu quan hệ truyền thống.\n",
    "Tuy nhiên, dữ liệu phi cấu trúc lại phong phú về mặt nội dung và có ứng dụng rộng rãi trong các bài toán phân tích và trí tuệ kinh doanh hiện đại.\n",
    "\n",
    "Các nguồn dữ liệu phi cấu trúc thường gặp bao gồm:\n",
    "\n",
    "-   Trang web\n",
    "\n",
    "-   Dữ liệu từ mạng xã hội\n",
    "\n",
    "-   Hình ảnh (JPEG, PNG, GIF,…)\n",
    "\n",
    "-   Tệp âm thanh, video\n",
    "\n",
    "-   Văn bản (PDF, Word, PowerPoint)\n",
    "\n",
    "Loại dữ liệu này thường được lưu trữ dưới dạng tệp văn bản, tài liệu, hoặc trong các cơ sở dữ liệu NoSQL – nơi cung cấp công cụ phân tích phù hợp với tính chất không có cấu trúc của dữ liệu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7b5473-b9b2-4e6f-84d8-fdd89146b03e",
   "metadata": {},
   "source": [
    "### Định dạng tệp chứa dữ liệu\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f816c-795f-45a3-b111-c5674d5588c7",
   "metadata": {},
   "source": [
    "Trong môi trường làm việc với dữ liệu, việc nắm bắt các định dạng tệp và cấu trúc dữ liệu là yếu tố thiết yếu nhằm bảo đảm hiệu quả trong lưu trữ, truy xuất và phân tích thông tin.\n",
    "Các định dạng tệp phổ biến được sử dụng bao gồm: tệp dữ liệu văn bản phân tách (delimited text), bảng tính Microsoft Excel, ngôn ngữ đánh dấu mở rộng (XML), định dạng tài liệu di động (PDF), và JavaScript Object Notation (JSON).\n",
    "\n",
    "-   **Tệp văn bản phân tách** lưu trữ dữ liệu dưới dạng văn bản thuần, trong đó mỗi dòng đại diện cho một bản ghi, và các giá trị trong dòng được phân tách bởi một ký tự đặc biệt gọi là dấu phân tách.\n",
    "    Các dấu phân tách phổ biến bao gồm dấu phẩy (,), tab, dấu hai chấm (:), thanh dọc (\\|), và dấu cách (space).\n",
    "    Các định dạng tệp CSV (Comma-Separated Values) và TSV (Tab-Separated Values) là những ví dụ điển hình.\n",
    "    Tệp CSV sử dụng dấu phẩy làm dấu phân tách, trong khi TSV sử dụng ký tự tab.\n",
    "    Tệp phân tách thường có dòng đầu tiên là tiêu đề của các cột và có thể xử lý dễ dàng bằng nhiều phần mềm phân tích dữ liệu.\n",
    "\n",
    "-   **Bảng tính Microsoft Excel** là định dạng bảng tính được phát triển bởi Microsoft.\n",
    "    Tệp dữ liệu thường gồm nhiều trang tính (worksheet), mỗi trang có cấu trúc hàng (row) và cột (column), trong đó ô dữ liệu (cell) là đơn vị cơ bản.\n",
    "    Bảng tính hỗ trợ nhiều chức năng tính toán, định dạng và bảo mật dữ liệu, đồng thời có khả năng tương thích cao với các phần mềm phân tích khác.\n",
    "\n",
    "-   **Ngôn ngữ đánh dấu mở rộng XML** là một ngôn ngữ đánh dấu có thể đọc được bởi cả con người và máy tính, XML cho phép mô tả dữ liệu theo cấu trúc phân cấp.\n",
    "    XML không sử dụng các thẻ (tag) được định nghĩa trước mà cho phép người dùng tự định nghĩa.\n",
    "    XML được sử dụng rộng rãi trong truyền tải dữ liệu qua Internet và có tính độc lập cao với nền tảng phần cứng hoặc ngôn ngữ lập trình.\n",
    "\n",
    "-   **Định dạng tài liệu di động** được phát triển bởi Adobe, còn được gọi là các file *.pdf*, là định dạng tiêu chuẩn để trình bày văn bản và hình ảnh một cách thống nhất, bất kể phần mềm, phần cứng hay hệ điều hành sử dụng.\n",
    "    PDF thường được dùng trong các tài liệu pháp lý, tài chính và biểu mẫu cần điền thông tin.\n",
    "\n",
    "-   **JavaScript Object Notation**, hay JSON, là định dạng văn bản nhẹ và dễ hiểu, được thiết kế để truyền tải dữ liệu có cấu trúc qua web.\n",
    "    JSON hỗ trợ lưu trữ dữ liệu dạng cặp khóa-giá trị và có tính tương thích cao với hầu hết các ngôn ngữ lập trình, đặc biệt phổ biến trong các giao diện lập trình ứng dụng và dịch vụ web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d0d127-53ac-491d-867e-d50564153f52",
   "metadata": {},
   "source": [
    "### Nguồn dữ liệu\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c79d99-7057-4a7c-a700-293db22d1b06",
   "metadata": {},
   "source": [
    "Dữ liệu ngày nay được sinh ra từ nhiều nguồn đa dạng và liên tục.\n",
    "Có thể phân loại các nguồn dữ liệu phổ biến như sau:\n",
    "\n",
    "-   **Cơ sở dữ liệu quan hệ** (relational databases) là nguồn dữ liệu có cấu trúc được lưu trữ trong các hệ quản trị cơ sở dữ liệu như SQL Server, Oracle, MySQL và IBM DB2.\n",
    "    Dữ liệu này có thể khai thác để phân tích giao dịch bán lẻ, quản trị quan hệ khách hàng, hay dự báo doanh số.\n",
    "\n",
    "-   **Tệp văn bản phẳng, bảng tính và XML** lưu trữ dữ liệu dưới dạng dòng văn bản, trong đó mỗi dòng là một bản ghi với các giá trị phân tách bằng dấu đặc biệt.\n",
    "    Bảng tính như Excel hoặc Google Sheets cung cấp khả năng lưu trữ dữ liệu dạng bảng, có thể kèm theo định dạng và công thức.\n",
    "    XML hỗ trợ cấu trúc dữ liệu phức tạp và thường dùng trong khảo sát, sao kê ngân hàng và dữ liệu phi cấu trúc.\n",
    "\n",
    "-   **API (Application Programming Interface) và dịch vụ Web** là các cổng kết nối cho phép người dùng hoặc ứng dụng truy cập dữ liệu từ hệ thống khác.\n",
    "    Ví dụ: API của Twitter hoặc Facebook để phân tích cảm xúc từ bài đăng; API thị trường chứng khoán để truy xuất dữ liệu giá, EPS, và lịch sử giao dịch.\n",
    "    \n",
    "-   **Web Scraping** là phương pháp trích xuất dữ liệu từ các trang web không có API công khai.\n",
    "    Các công cụ phổ biến gồm Scrapy, và Selenium.\n",
    "    Web scraping được dùng trong so sánh giá, thu thập dữ liệu khách hàng, hoặc tạo tập dữ liệu huấn luyện cho mô hình học máy.\n",
    "\n",
    "-   **Dữ liệu từ các nguồn cấp khác**: được truyền liên tục từ các thiết bị IoT, hệ thống GPS, cảm biến, camera an ninh, và mạng xã hội.\n",
    "    Ứng dụng trong phân tích thời gian thực như giao dịch tài chính, giám sát an ninh, và quản lý chuỗi cung ứng.\n",
    "    Các nền tảng như Apache Kafka, Spark Streaming và Storm thường được dùng để xử lý dạng dữ liệu này."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d2353c-0e3a-4839-9e97-e32cb4756e2c",
   "metadata": {},
   "source": [
    "### Ngôn ngữ máy tính cho chuyên gia dữ liệu\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9e6297-1d54-48ef-9d77-422473f98e20",
   "metadata": {},
   "source": [
    "Ngôn ngữ lập trình và truy vấn dữ liệu đóng vai trò trung tâm trong hoạt động phân tích và xử lý dữ liệu.\n",
    "Ba loại ngôn ngữ phổ biến bao gồm:\n",
    "\n",
    "-   **Ngôn ngữ truy vấn**, chẳng hạn như SQL (structured query language), là ngôn ngữ tiêu chuẩn để truy xuất và thao tác với dữ liệu trong cơ sở dữ liệu quan hệ.\n",
    "    SQL cho phép thực hiện các thao tác như tạo bảng, chèn, cập nhật và truy vấn dữ liệu với cú pháp gần gũi ngôn ngữ tự nhiên.\n",
    "\n",
    "-   **Ngôn ngữ lập trình**:\n",
    "\n",
    "    -   Python: Là ngôn ngữ lập trình thông dụng, mã nguồn mở, cú pháp đơn giản, dễ học. Python sở hữu hệ sinh thái thư viện phong phú như NumPy, Pandas, Matplotlib, Seaborn, Scikit-learn cho khoa học dữ liệu và học máy.\n",
    "    -   R: Là ngôn ngữ chuyên biệt cho thống kê và trực quan hóa dữ liệu, với các thư viện như ggplot2, dplyr, và Shiny hỗ trợ xây dựng ứng dụng phân tích tương tác.\n",
    "\n",
    "-   **Ngôn ngữ shell và script**:\n",
    "\n",
    "    -   Unix/Linux Shell: Cho phép tự động hóa các tác vụ lặp lại như sao lưu, xử lý tệp và giám sát hệ thống.\n",
    "    -   PowerShell: Được Microsoft phát triển, hỗ trợ làm việc với dữ liệu có cấu trúc như JSON, XML, REST API và có thể dùng để tạo dashboard, báo cáo và GUI tương tác.\n",
    "\n",
    "Như vậy, việc lựa chọn và sử dụng thành thạo một số ngôn ngữ trong ba nhóm trên là yêu cầu thiết yếu đối với bất kỳ chuyên gia dữ liệu nào nhằm phục vụ hiệu quả cho quá trình khai thác, xử lý và phân tích dữ liệu trong môi trường thực tiễn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4493078-3a31-4c0c-9c69-d82536b487be",
   "metadata": {},
   "source": [
    "## Kho lưu trữ dữ liệu\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cfe424-225a-421c-8d70-41321e267851",
   "metadata": {},
   "source": [
    "Kho dữ liệu, hay data repository, là một thuật ngữ tổng quát chỉ hệ thống lưu trữ dữ liệu đã được thu thập, tổ chức và cách ly nhằm phục vụ cho hoạt động vận hành doanh nghiệp, hoặc để phân tích và khai phá thông tin nhằm hỗ trợ ra quyết định.\n",
    "Kho dữ liệu có thể là một cơ sở dữ liệu đơn lẻ hoặc một hạ tầng cơ sở dữ liệu phức hợp bao gồm nhiều hệ thống quản lý dữ liệu khác nhau, từ quy mô nhỏ đến rất lớn.\n",
    "\n",
    "Có nhiều dạng kho dữ liệu mà dữ liệu có thể được lưu trữ, trong đó đáng chú ý là cơ sở dữ liệu (database), kho dữ liệu doanh nghiệp (data warehouse), và các hệ thống lưu trữ dữ liệu lớn (big data stores).\n",
    "Các hệ thống này sẽ được trình bày chi tiết hơn ở các phần tiếp theo.\n",
    "\n",
    "Cơ sở dữ liệu là tập hợp có cấu trúc của dữ liệu, được thiết kế để thực hiện các thao tác nhập liệu, lưu trữ, tìm kiếm, truy vấn và cập nhật dữ liệu một cách hiệu quả.\n",
    "Hệ quản trị cơ sở dữ liệu là tập hợp các chương trình phần mềm giúp tạo lập, duy trì và thao tác trên cơ sở dữ liệu, cho phép người dùng truy xuất, chỉnh sửa và trích xuất thông tin từ cơ sở dữ liệu thông qua các truy vấn.\n",
    "\n",
    "Chẳng hạn, nếu doanh nghiệp cần truy xuất danh sách khách hàng không hoạt động trong 6 tháng trở lên, một câu truy vấn sẽ được DBMS xử lý để trả về danh sách các khách hàng thỏa điều kiện đó.\n",
    "Mặc dù cơ sở dữ liệu và DBMS là hai khái niệm khác nhau, chúng thường được sử dụng thay thế cho nhau trong thực tế.\n",
    "\n",
    "Việc lựa chọn loại cơ sở dữ liệu phụ thuộc vào nhiều yếu tố như kiểu và cấu trúc dữ liệu, cơ chế truy vấn, độ trễ cho phép, tốc độ xử lý giao dịch, và mục đích sử dụng.\n",
    "Hai loại cơ sở dữ liệu chính hiện nay là: cơ sở dữ liệu quan hệ (relational databases) và cơ sở dữ liệu phi quan hệ (non-relational databases hoặc NoSQL).\n",
    "\n",
    "-   **Cơ sở dữ liệu quan hệ** tổ chức dữ liệu theo dạng bảng (table), mỗi bảng gồm các hàng (records) và cột (attributes), tuân thủ một mô hình dữ liệu chặt chẽ với lược đồ xác định.\n",
    "    RDBMS tối ưu hóa cho các thao tác truy vấn phức tạp và dữ liệu có khối lượng lớn.\n",
    "    Ngôn ngữ truy vấn có cấu trúc (SQL - Structured Query Language) là ngôn ngữ tiêu chuẩn được sử dụng trong RDBMS.\n",
    "\n",
    "-   **Cơ sở dữ liệu phi quan hệ** ra đời nhằm đáp ứng yêu cầu lưu trữ và xử lý khối lượng lớn dữ liệu đa dạng về hình thức và tốc độ sinh dữ liệu ngày càng cao trong bối cảnh điện toán đám mây, Internet vạn vật (IoT), và mạng xã hội phát triển.\n",
    "    Không giống như RDBMS, NoSQL cho phép lưu trữ dữ liệu không có cấu trúc cố định và hỗ trợ khả năng mở rộng linh hoạt theo chiều ngang.\n",
    "\n",
    "**Kho dữ liệu doanh nghiệp**, hay data warehouse, là một kho lưu trữ trung tâm hợp nhất dữ liệu từ nhiều nguồn khác nhau, xử lý thông qua quy trình trích xuất, chuyển đổi và load dữ liệu, nhằm tạo ra một cơ sở dữ liệu duy nhất phục vụ cho phân tích và khai thác thông tin chiến lược.\n",
    "Kho dữ liệu doanh nghiệp thường được sử dụng trong hệ thống thông tin quản trị và hỗ trợ ra quyết định.\n",
    "\n",
    "Liên quan đến kho dữ liệu còn có các khái niệm như data mart và data lake, sẽ được trình bày chi tiết trong các phần sau.\n",
    "Trong khi Kho dữ liệu doanh nghiệp chủ yếu sử dụng các công nghệ quan hệ truyền thống, thì với sự xuất hiện của các công nghệ NoSQL và các loại dữ liệu mới, hiện nay nhiều hệ thống Kho dữ liệu doanh nghiệp cũng tích hợp các kho dữ liệu phi quan hệ.\n",
    "\n",
    "Kho dữ liệu lớn là hạ tầng lưu trữ và tính toán phân tán, được thiết kế để lưu trữ, mở rộng và xử lý các tập dữ liệu khổng lồ.\n",
    "Các kho dữ liệu này cho phép xử lý song song và phân phối dữ liệu trên nhiều nodes trong mạng, đảm bảo khả năng mở rộng quy mô và tính sẵn sàng cao."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40293080-c3f2-4416-9496-312bf0c075a7",
   "metadata": {},
   "source": [
    "### Cơ sở dữ liệu quan hệ\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85228d77-5685-4906-8c1a-ee12415beb31",
   "metadata": {},
   "source": [
    "Cơ sở dữ liệu quan hệ là một kiểu tổ chức dữ liệu theo cấu trúc bảng, trong đó các bảng có thể liên kết với nhau thông qua các thuộc tính chung.\n",
    "Mỗi bảng gồm các hàng, rows hay records, và cột, column hay attributes.\n",
    "Ví dụ như bảng khách hàng có thể bao gồm các cột như mã khách hàng, tên công ty, địa chỉ, và số điện thoại liên hệ chính, với mỗi hàng tương ứng với một khách hàng cụ thể.\n",
    "\n",
    "Sự liên kết giữa các bảng dựa trên khóa ngoại (foreign keys) là yếu tố cốt lõi trong mô hình quan hệ.\n",
    "Ví dụ, bảng giao dịch có thể bao gồm các cột như ngày giao dịch, mã khách hàng, số tiền, và phương thức thanh toán; bảng này có thể liên kết với bảng khách hàng thông qua mã khách hàng.\n",
    "Khả năng tạo ra các bảng mới thông qua truy vấn kết hợp từ nhiều bảng giúp người dùng khai thác dữ liệu hiệu quả, phát hiện mối quan hệ giữa các đối tượng và hỗ trợ ra quyết định chính xác hơn.\n",
    "\n",
    "Cơ sở dữ liệu quan hệ sử dụng ngôn ngữ SQL để truy vấn, cập nhật, và quản lý dữ liệu.\n",
    "Khác với bảng tính bị giới hạn về quy mô và chức năng, cơ sở dữ liệu quan hệ được thiết kế để xử lý dữ liệu ở quy mô lớn, với khả năng kiểm soát kiểu dữ liệu và giới hạn giá trị nhằm đảm bảo tính nhất quán và toàn vẹn của dữ liệu.\n",
    "\n",
    "Các hệ thống cơ sở dữ liệu quan hệ phổ biến hiện nay bao gồm: MySQL, PostgreSQL, Microsoft SQL Server, và Oracle Database.\n",
    "Trong môi trường đám mây, các dịch vụ như Amazon RDS, Google Cloud SQL, Oracle Cloud, và SQL Azure ngày càng được ưa chuộng nhờ khả năng mở rộng linh hoạt và khả năng sao lưu liên tục.\n",
    "\n",
    "Cơ sở dữ liệu quan hệ là một công nghệ đã phát triển, có tài liệu phong phú và cộng đồng người dùng lớn, giúp việc đào tạo và tuyển dụng trở nên dễ dàng.\n",
    "Một số ưu điểm nổi bật của cơ sở dữ liệu quan hệ bao gồm:\n",
    "\n",
    "-   **Tính linh hoạt**: cho phép thêm bảng, thêm cột, đổi tên, và chỉnh sửa trong khi cơ sở dữ liệu vẫn đang hoạt động.\n",
    "\n",
    "-   **Giảm thiểu dư thừa dữ liệu**: dữ liệu được chuẩn hóa, ví dụ như thông tin khách hàng chỉ lưu một lần trong bảng khách hàng, còn bảng giao dịch chỉ lưu mã liên kết.\n",
    "\n",
    "-   **Hỗ trợ sao lưu và phục hồi**: cho phép xuất và nhập dữ liệu dễ dàng, đồng thời có thể thiết lập cơ chế sao lưu liên tục trong môi trường đám mây.\n",
    "\n",
    "-   **Tuân thủ ACID**: bảo đảm tính toàn vẹn và nhất quán của dữ liệu thông qua các thuộc tính nguyên tử (Atomicity), nhất quán (Consistency), cô lập (Isolation), và bền vững (Durability).\n",
    "\n",
    "Tuy nhiên, cơ sở dữ liệu quan hệ cũng tồn tại một số hạn chế, như khó khăn trong việc xử lý dữ liệu phi cấu trúc hoặc bán cấu trúc, yêu cầu sự tương thích hoàn toàn về lược đồ khi di chuyển giữa các hệ thống, và giới hạn về độ dài của các trường dữ liệu.\n",
    "Dù vậy, cơ sở dữ liệu quan hệ vẫn giữ vai trò trung tâm trong các hệ thống xử lý dữ liệu có cấu trúc nhờ độ tin cậy cao và khả năng tích hợp tốt với các công nghệ truyền thống và hiện đại."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a472a-47a6-4a50-a256-2c1746ffde12",
   "metadata": {},
   "source": [
    "### Cơ sở dữ liệu phi quan hệ\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad4f882-1181-4de2-ac94-403fd6426a54",
   "metadata": {},
   "source": [
    "Cơ sở dữ liệu phi quan hệ là một nhóm các hệ thống quản lý dữ liệu phi quan hệ, được thiết kế nhằm cung cấp khả năng lưu trữ và truy xuất dữ liệu với cấu trúc linh hoạt, không tuân thủ chặt chẽ các mô hình quan hệ truyền thống.\n",
    "Thuật ngữ “NoSQL” không có nghĩa phủ định việc sử dụng SQL, mà phản ánh sự mở rộng phạm vi của cơ sở dữ liệu vượt ra ngoài các hệ thống chỉ sử dụng SQL, cho phép xử lý dữ liệu phi cấu trúc và bán cấu trúc với quy mô lớn và tốc độ cao.\n",
    "\n",
    "NoSQL ngày càng được ứng dụng rộng rãi trong bối cảnh các hệ thống điện toán đám mây, dữ liệu lớn, mạng xã hội và các ứng dụng web hoặc di động có lưu lượng người dùng cao.\n",
    "Không giống như cơ sở dữ liệu quan hệ, các hệ thống NoSQL không yêu cầu định nghĩa trước lược đồ, đồng thời hỗ trợ nhiều mô hình lưu trữ dữ liệu khác nhau, từ đó mang lại sự linh hoạt trong thiết kế và khả năng mở rộng ngang cao.\n",
    "\n",
    "Các mô hình chính của NoSQL bao gồm:\n",
    "\n",
    "-   **Cơ sở dữ liệu dạng khóa–giá trị**, hay key–value stores, lưu trữ dữ liệu dưới dạng các cặp khóa và giá trị.\n",
    "    Mỗi khóa là một định danh duy nhất, ánh xạ tới một giá trị có thể là kiểu đơn giản như chuỗi, số hoặc cấu trúc phức hợp như tài liệu JSON.\n",
    "    Mô hình này đơn giản nhưng cực kỳ hiệu quả đối với các ứng dụng yêu cầu truy cập dữ liệu nhanh, chẳng hạn như lưu trữ phiên làm việc của người dùng, cấu hình hệ thống, bộ nhớ đệm, và quản lý trạng thái.\n",
    "    Một số ví dụ tiêu biểu bao gồm Redis, Memcached và Amazon DynamoDB. Tuy nhiên, mô hình khóa–giá trị không phù hợp nếu cần tìm kiếm theo thuộc tính hoặc thiết lập quan hệ giữa các thực thể dữ liệu.\n",
    "\n",
    "-   **Cơ sở dữ liệu dạng tài liệu**, hay document stores, lưu trữ dữ liệu dưới dạng các tài liệu độc lập, thường sử dụng định dạng JSON, BSON hoặc XML.\n",
    "    Mỗi tài liệu chứa dữ liệu và siêu dữ liệu liên quan, có thể có cấu trúc khác nhau giữa các tài liệu trong cùng một collection.\n",
    "    Mô hình này rất phù hợp với các ứng dụng yêu cầu tính linh hoạt trong thiết kế dữ liệu như hệ thống thương mại điện tử, nền tảng phân tích văn bản, quản lý hồ sơ bệnh án, hoặc các hệ thống CRM.\n",
    "    Các hệ thống nổi bật gồm MongoDB, CouchDB, Amazon DocumentDB, và IBM Cloudant.\n",
    "    Mặc dù hỗ trợ tìm kiếm linh hoạt và chỉ mục tùy chỉnh, các hệ quản trị này có thể gặp hạn chế về hiệu năng khi xử lý các giao dịch phức tạp hoặc truy vấn nhiều bảng.\n",
    "\n",
    "-   **Cơ sở dữ liệu dạng cột**, hay column-oriented stores, lưu trữ dữ liệu theo từng cột thay vì từng hàng, giúp tăng tốc độ truy xuất dữ liệu trong các trường hợp cần xử lý các truy vấn lớn theo chiều dọc.\n",
    "    Các cột thường được nhóm thành \"họ cột\", phản ánh các trường dữ liệu có xu hướng được truy xuất cùng nhau.\n",
    "    Mô hình này rất thích hợp cho các ứng dụng cần ghi dữ liệu với tần suất cao, lưu trữ dữ liệu thời gian thực, hoặc xử lý dữ liệu từ các thiết bị IoT.\n",
    "    Một số hệ thống tiêu biểu gồm Apache Cassandra và HBase.\n",
    "    Tuy nhiên, mô hình này có thể không phù hợp nếu cần hỗ trợ truy vấn linh hoạt với cấu trúc dữ liệu thay đổi thường xuyên.\n",
    "\n",
    "-   **Cơ sở dữ liệu dạng đồ thị**, hay graph databases, được thiết kế để mô hình hóa dữ liệu và các mối quan hệ giữa dữ liệu dưới dạng các đỉnh (nodes) và cạnh (edges).\n",
    "    Mỗi đỉnh đại diện cho một thực thể, trong khi các cạnh biểu thị mối quan hệ giữa các thực thể.\n",
    "    Cách tổ chức này cho phép thực hiện hiệu quả các truy vấn về kết nối, chẳng hạn như tìm đường đi ngắn nhất, phát hiện cộng đồng trong mạng xã hội, hoặc phân tích mối quan hệ giữa các thực thể trong hệ thống quản lý truy cập.\n",
    "    Các hệ thống nổi bật trong nhóm này bao gồm Neo4j, Amazon Neptune và Azure Cosmos DB. Tuy nhiên, cơ sở dữ liệu đồ thị có thể không lý tưởng cho các ứng dụng yêu cầu xử lý giao dịch lớn hoặc phân tích dữ liệu khối lượng cao theo cách tổng hợp.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f2145c-74b9-4afc-aebf-1da0178252f5",
   "metadata": {},
   "source": [
    "### Data mart, data lake, quy trình ETL và data pipelines\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f137da-a203-455c-9ea7-0f61e8bbd463",
   "metadata": {},
   "source": [
    "Trong bối cảnh hiện đại, khi dữ liệu ngày càng đóng vai trò trung tâm trong việc ra quyết định, các tổ chức cần xây dựng các kiến trúc lưu trữ và xử lý dữ liệu một cách có hệ thống và hiệu quả.\n",
    "Bốn thành phần quan trọng trong hệ sinh thái dữ liệu hiện đại bao gồm: data mart, data lake, quy trình Extract – Transform – Load, và data pipeline.\n",
    "Mỗi thành phần đảm nhận một vai trò riêng trong việc quản lý, tích hợp và phục vụ dữ liệu cho các mục tiêu phân tích, dự báo và ra quyết định.\n",
    "\n",
    "-   **Kho dữ liệu chuyên biệt**, hay data mart, là một phần con được trích lọc từ kho dữ liệu tổng thể (data warehouse), được xây dựng để phục vụ một mục đích phân tích cụ thể hoặc một bộ phận chức năng trong tổ chức, chẳng hạn như tài chính, nhân sự, marketing, hoặc bán hàng.\n",
    "    Các data mart thường có quy mô nhỏ hơn, phạm vi chuyên biệt, và được tối ưu hóa cho các truy vấn đặc thù của từng nhóm người dùng.\n",
    "    Việc triển khai Data Mart giúp giảm độ phức tạp trong truy vấn, cải thiện hiệu năng truy xuất, đồng thời tăng tính bảo mật dữ liệu bằng cách giới hạn phạm vi truy cập theo vai trò.\n",
    "    Các data mart có thể được xây dựng theo hướng độc lập hoặc được trích xuất từ kho dữ liệu trung tâm.\n",
    "\n",
    "-   **Hồ dữ liệu**, hay data lake, là kho lưu trữ dữ liệu linh hoạt, có khả năng chứa dữ liệu ở nhiều định dạng và mức độ xử lý khác nhau, bao gồm dữ liệu có cấu trúc, bán cấu trúc, và phi cấu trúc.\n",
    "    Khác với kho dữ liệu, vốn yêu cầu chuẩn hóa và mô hình hóa dữ liệu trước khi lưu trữ, data lake cho phép giữ nguyên trạng thái gốc của dữ liệu – một đặc điểm quan trọng trong các ứng dụng phân tích dữ liệu lớn và mô hình học máy.\n",
    "    Mỗi phần tử dữ liệu trong data lake thường được gắn với một định danh duy nhất cùng với metadata mô tả, cho phép truy xuất linh hoạt và hỗ trợ tích hợp dễ dàng với các công cụ phân tích hiện đại.\n",
    "    Data lake thường được xây dựng trên các hệ thống lưu trữ phân tán như Hadoop Distributed File System hoặc Amazon S3.\n",
    "\n",
    "-   **Quy trình Extract – Transform – Load** là quy trình kỹ thuật then chốt trong việc chuyển đổi dữ liệu từ trạng thái thô sang trạng thái có thể phân tích được.\n",
    "    Quy trình này bao gồm ba bước chính:\n",
    "\n",
    "    -   Extract (Trích xuất): Dữ liệu được thu thập từ nhiều nguồn khác nhau như cơ sở dữ liệu giao dịch, tập tin CSV, API, thiết bị IoT, hoặc các hệ thống web. Việc trích xuất có thể thực hiện theo kiểu hàng loạt (batch processing) hoặc thời gian thực (streaming).\n",
    "    -   Transform (Biến đổi): Dữ liệu được xử lý để làm sạch, chuẩn hóa định dạng, lọc bỏ thông tin không cần thiết, chuyển đổi đơn vị, mã hóa dữ liệu nhạy cảm, và xây dựng các mối liên kết giữa các bảng. Đây là bước quan trọng để đảm bảo tính nhất quán và toàn vẹn của dữ liệu.\n",
    "    -   Load (Tải vào): Dữ liệu đã xử lý được tải vào các kho lưu trữ đích như Data Warehouse hoặc Data Lake. Quá trình nạp có thể là toàn bộ (full load), gia tăng (incremental load), hoặc làm mới (refresh). Việc xác minh và giám sát sau khi nạp dữ liệu là cần thiết để đảm bảo chất lượng dữ liệu và phát hiện lỗi tải (load failures).\n",
    "\n",
    "-   **Pipeline dữ liệu**, hay data pipeline, là một hệ thống kỹ thuật toàn diện, đảm nhiệm việc di chuyển, chuyển đổi và phân phối dữ liệu từ nhiều nguồn đến các đích khác nhau.\n",
    "    Mặc dù thuật ngữ \"ETL\" thường được sử dụng thay thế cho \"data pipeline\", song data pipeline mang tính khái quát và linh hoạt hơn, cũng như các kiến trúc xử lý theo luồng.\n",
    "    Một Data Pipeline điển hình có thể bao gồm:\n",
    "\n",
    "    -   Thu thập dữ liệu từ nhiều nguồn khác nhau\n",
    "    -   Chuyển đổi định dạng dữ liệu và áp dụng logic nghiệp vụ\n",
    "    -   Đồng bộ hóa dữ liệu theo lịch trình hoặc theo sự kiện\n",
    "    -   Tích hợp với các nền tảng lưu trữ hoặc hiển thị như dashboard, mô hình học máy, hoặc hệ thống ra quyết định\n",
    "\n",
    "Các công nghệ phổ biến hỗ trợ triển khai Pipeline dữ liệu bao gồm Apache Kafka, Apache Beam, Google Cloud Dataflow, và AWS Glue.\n",
    "Trong môi trường dữ liệu hiện đại, pipelines thường được thiết kế theo kiến trúc hướng sự kiện (event-driven), hỗ trợ khả năng mở rộng, chống lỗi, và giám sát tự động."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64fa894-577f-4967-8a91-c692ef246baf",
   "metadata": {},
   "source": [
    "### Nền tảng dữ liệu lớn\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dda870-774a-4967-b9e1-2c82a6daa1a7",
   "metadata": {},
   "source": [
    "Trong kỷ nguyên số, dữ liệu phát sinh từ mọi hoạt động của con người, thiết bị và hệ thống.\n",
    "Sự gia tăng đột biến về lượng dữ liệu đã làm nảy sinh khái niệm dữ liệu lớn, hay Big data, một lĩnh vực trung tâm trong phân tích hiện đại, yêu cầu những công nghệ mới nhằm thu thập, lưu trữ, xử lý và khai thác dữ liệu ở quy mô chưa từng có.\n",
    "\n",
    "Theo định nghĩa của Ernst & Young, dữ liệu lớn là tập hợp dữ liệu có kích thước lớn, tốc độ sinh dữ liệu nhanh, đến từ nhiều nguồn khác nhau và có mức độ phức tạp cao.\n",
    "Các tổ chức cần đến các công nghệ có tính đổi mới và có khả năng mở rộng để lưu trữ, xử lý và khai phá dữ liệu nhằm phục vụ các mục tiêu kinh doanh theo thời gian thực.\n",
    "\n",
    "Có năm đặc trưng cốt lõi giúp phân biệt dữ liệu lớn với các tập dữ liệu truyền thống, được gọi là nguyên tắc **5V**:\n",
    "\n",
    "-   **Volume**: dữ liệu lớn bao gồm khối lượng dữ liệu khổng lồ phát sinh từ thiết bị di động, cảm biến IoT, mạng xã hội, giao dịch trực tuyến, video và các nguồn số hóa khác. Ví dụ, mỗi ngày thế giới tạo ra khoảng 2.5 quintillion byte dữ liệu, tương đương với hàng triệu đĩa Blu-ray.\n",
    "-   **Velocity**: dữ liệu được tạo ra, xử lý và truyền tải với tốc độ rất cao. Công nghệ truyền phát dữ liệu theo thời gian thực (real-time streaming) như Apache Kafka hoặc Amazon Kinesis cho phép xử lý tức thì các dòng dữ liệu mới sinh.\n",
    "-   **Variety**: dữ liệu có thể ở nhiều định dạng: có cấu trúc (structured), bán cấu trúc (semi-structured) và phi cấu trúc (unstructured). Các loại dữ liệu bao gồm văn bản, hình ảnh, video, âm thanh, dữ liệu vị trí, và dữ liệu cảm biến.\n",
    "-   **Veracity**: dữ liệu lớn có thể chứa nhiều thông tin gây nhiễu, thiếu chính xác hoặc không nhất quán. Do đó, cần có các cơ chế kiểm soát chất lượng, đánh giá độ tin cậy và chuẩn hóa dữ liệu để đảm bảo kết quả phân tích chính xác.\n",
    "-   **Value**: giá trị cuối cùng của dữ liệu lớn được thể hiện thông qua khả năng chuyển hóa dữ liệu thô thành thông tin có ích cho ra quyết định, tối ưu hóa hiệu suất, phát hiện xu hướng, hoặc cung cấp dịch vụ thông minh.\n",
    "\n",
    "Để xử lý dữ liệu lớn, các tổ chức sử dụng một hệ sinh thái công nghệ được thiết kế dành riêng cho khả năng lưu trữ phân tán, tính toán song song và phân tích quy mô lớn.\n",
    "Dưới đây là ba công nghệ mã nguồn mở nổi bật:\n",
    "\n",
    "-   **Apache Hadoop** là một hệ sinh thái phần mềm mã nguồn mở hỗ trợ lưu trữ và xử lý dữ liệu lớn trên một cụm các máy tính phổ thông. Thành phần cốt lõi là Hadoop Distributed File System – một hệ thống tập tin phân tán, cho phép chia nhỏ tập dữ liệu lớn và lưu trữ chúng trên nhiều nút. Dữ liệu được nhân bản tự động nhằm đảm bảo tính sẵn sàng và khả năng chịu lỗi.\n",
    "-   **Hadoop** cung cấp nền tảng lưu trữ linh hoạt cho cả dữ liệu có cấu trúc và không có cấu trúc, hỗ trợ mô hình xử lý song song, giúp tối ưu hiệu suất và giảm tải trên hệ thống mạng thông qua chiến lược đưa tính toán đến gần dữ liệu.\n",
    "-   **Apache Hive** là một hệ thống kho dữ liệu được xây dựng trên nền Hadoop, cung cấp giao diện giống như SQL để truy vấn và phân tích dữ liệu lớn lưu trữ trong HDFS.\\\n",
    "    Hive thích hợp cho các tác vụ phân tích mang tính tổng hợp như báo cáo định kỳ, ETL và trực quan hóa dữ liệu, nhưng không phù hợp với các truy vấn thời gian thực hoặc các giao dịch phức tạp.\n",
    "-   **Apache Spark** là một nền tảng xử lý dữ liệu phân tán có hiệu năng cao, hỗ trợ cả xử lý hàng loạt và dữ liệu thời gian thực. Spark sử dụng kỹ thuật tính toán trong bộ nhớ để cải thiện tốc độ xử lý, đặc biệt hữu ích trong các tác vụ học máy, phân tích thời gian thực và xử lý dòng dữ liệu. Spark hỗ trợ đa ngôn ngữ lập trình (Scala, Python, Java, R, SQL) và có thể tích hợp với Hadoop, Hive, và các hệ thống lưu trữ khác, cho phép người dùng xây dựng các pipeline phân tích linh hoạt và hiệu quả.\n",
    "\n",
    "Dữ liệu lớn đã trở thành công cụ không thể thiếu và đặc biệt hiệu quả trong các lĩnh vực:\n",
    "\n",
    "-   Phân tích hành vi người tiêu dùng qua dữ liệu mạng xã hội, mua sắm trực tuyến;\n",
    "-   Dự báo bảo trì trong công nghiệp thông qua dữ liệu cảm biến;\n",
    "-   Phân tích y tế và hệ gen với dữ liệu sức khỏe lớn và phức tạp;\n",
    "-   Phát hiện gian lận trong tài chính thông qua phân tích thời gian thực và học máy);\n",
    "-   Ra quyết định trong quản trị công dựa trên dữ liệu từ thiết bị IoT, camera, và nền tảng số."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c9141a-40f6-4e7e-8d28-4bf492a8ad96",
   "metadata": {},
   "source": [
    "## Các vị trí công việc trong khoa học dữ liệu\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de1c433-c754-477d-b7fa-7b20db8d28e4",
   "metadata": {},
   "source": [
    "### Chuyên gia phân tích dữ liệu\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b70e77c-bf68-4867-8e01-15840465442e",
   "metadata": {},
   "source": [
    "Nghề nghiệp trong lĩnh vực phân tích dữ liệu đang phát triển mạnh mẽ trên toàn cầu, với nhu cầu tuyển dụng ngày càng tăng trong cả khu vực công nghiệp, chính phủ và học thuật.\n",
    "Từ tài chính – ngân hàng, bảo hiểm, y tế, bán lẻ đến công nghệ thông tin, mọi ngành đều cần đến những nhà phân tích dữ liệu có chuyên môn.\n",
    "Không chỉ các tập đoàn lớn mà cả các công ty khởi nghiệp và doanh nghiệp đổi mới sáng tạo cũng ngày càng tìm kiếm nhân sự có kỹ năng dữ liệu.\n",
    "\n",
    "Theo báo cáo của Forbes, thị trường phân tích dữ liệu lớn toàn cầu đạt 37,34 tỷ USD năm 2018, và dự kiến tăng trưởng với tốc độ kép hàng năm (CAGR) là 12,3% trong giai đoạn 2019–2027, đạt 105,08 tỷ USD vào năm 2027.\n",
    "Trong bối cảnh đó, nguồn cung nhân lực chưa đáp ứng được nhu cầu thị trường, dẫn đến việc nhiều doanh nghiệp sẵn sàng trả mức đãi ngộ cao để thu hút nhân sự có năng lực phân tích dữ liệu.\n",
    "\n",
    "Lộ trình nghề nghiệp trong phân tích dữ liệu có thể được chia thành ba nhóm chính:\n",
    "\n",
    "-   Nhà phân tích dữ liệu chuyên sâu (Data Analyst Specialist)\n",
    "-   Chuyên gia phân tích theo ứng dụng (Domain/Functional Analyst)\n",
    "-   Các vị trí công việc được tăng cường bởi dữ liệu (Analytics-enabled roles)\n",
    "\n",
    "**Nhà phân tích dữ liệu chuyên sâu** là con đường dành cho những người mong muốn phát triển chuyên môn sâu về kỹ thuật và quy trình phân tích.\n",
    "Một lộ trình điển hình bắt đầu từ Associate / Junior Data Analyst, tiếp tục qua các cấp độ Analyst → Senior Analyst → Lead Analyst → Principal Analyst.\n",
    "Trong các tổ chức nhỏ, một nhà phân tích thường đảm nhận toàn bộ chu trình từ thu thập đến trực quan hóa dữ liệu, điều này giúp họ tích lũy kinh nghiệm đa chiều nhanh chóng.\n",
    "Trong tổ chức lớn, công việc thường được phân chia theo giai đoạn, giúp người phân tích có thể chuyên sâu từng kỹ năng trước khi mở rộng sang giai đoạn khác.\n",
    "Khi thăng tiến lên các cấp độ cao hơn, nhà phân tích cần phát triển năng lực ở nhiều khía cạnh:\n",
    "\n",
    "-   **Kỹ thuật**: Làm chủ nhiều ngôn ngữ lập trình, công cụ truy vấn (SQL), nền tảng dữ liệu (relational, NoSQL, cloud) và phần mềm trực quan hóa.\n",
    "-   **Kỹ năng mềm**: Kỹ năng giao tiếp, trình bày, quản lý dự án và làm việc với các bên liên quan (stakeholders).\n",
    "-   **Năng lực quản lý**: Thiết lập quy trình, đề xuất công nghệ, huấn luyện nhóm, và mở rộng đội ngũ.\n",
    "\n",
    "**Chuyên gia phân tích theo ứng dụng** yêu cầu kiến thức sâu về lĩnh vực ứng dụng cụ thể như: y tế, tài chính, tiếp thị, bán hàng, mạng xã hội...\n",
    "Các vị trí điển hình bao gồm: Healthcare Analyst, Marketing Analyst, Sales Analyst, hoặc Social Media Analyst.\n",
    "Dù có thể không quá chuyên sâu về kỹ thuật, các nhà phân tích theo miền thường được đánh giá cao nhờ khả năng kết nối phân tích với bối cảnh thực tế và quyết định nghiệp vụ.\n",
    "\n",
    "**Các vị trí công việc được tăng cường bởi dữ liệu** là các vị trí truyền thống như Quản lý dự án, giám đốc tiếp thị, quản lý nhân sự, được tăng cường hiệu quả nhờ năng lực phân tích.\n",
    "Ngày càng nhiều doanh nghiệp đòi hỏi năng lực phân tích dữ liệu như một phần của bộ kỹ năng thiết yếu, dẫn đến sự mở rộng mạnh mẽ của các vị trí như vậy..\n",
    "\n",
    "Nhìn chung, nghề phân tích dữ liệu là một lĩnh vực rộng lớn, năng động và có tính liên ngành cao.\n",
    "Lộ trình phát triển sự nghiệp trong ngành này không mang tính tuyến tính mà cho phép di chuyển ngang, đi sâu theo chuyên môn hoặc mở rộng theo chiều rộng nghiệp vụ.\n",
    "Điều quan trọng là bạn cần liên tục học hỏi, sẵn sàng thích nghi với công nghệ mới, và tích lũy kinh nghiệm thực tiễn thông qua dự án và thực hành.\n",
    "Với lượng tài nguyên đào tạo khổng lồ và cộng đồng hỗ trợ sôi động, mọi cá nhân đều có cơ hội bước vào ngành phân tích dữ liệu – bất kể nền tảng xuất phát.\n",
    "Sự kết hợp giữa tư duy phân tích, khả năng kỹ thuật, hiểu biết nghiệp vụ và giao tiếp hiệu quả chính là chìa khóa dẫn đến thành công bền vững trong nghề nghiệp này."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3014d2c5-5989-4856-863f-259f13361ca2",
   "metadata": {},
   "source": [
    "### Kỹ sư dữ liệu\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06652da6-d25d-4483-bb4a-32e3ffbd55a8",
   "metadata": {},
   "source": [
    "Kỹ sư dữ liệu là một trong những vai trò then chốt trong hệ sinh thái dữ liệu hiện đại, chịu trách nhiệm xây dựng, tối ưu hóa và duy trì các hệ thống lưu trữ, xử lý và truyền dẫn dữ liệu phục vụ cho các hoạt động phân tích và ra quyết định.\n",
    "Trong bối cảnh mà dữ liệu ngày càng trở nên phong phú, đa dạng và có tốc độ sinh ra cao, kỹ sư dữ liệu đóng vai trò là người thiết kế hạ tầng, đảm bảo dữ liệu đến đúng nơi, đúng lúc và ở đúng định dạng.\n",
    "\n",
    "Nhu cầu về kỹ sư dữ liệu tăng mạnh song song với sự phát triển của các hệ thống dữ liệu lớn, phân tích thời gian thực, và mô hình học máy triển khai ở quy mô lớn.\n",
    "Các tổ chức hiện đại ngày càng đầu tư vào việc xây dựng pipeline dữ liệu tự động, ổn định và có khả năng mở rộng, khiến vai trò của kỹ sư dữ liệu trở thành yếu tố không thể thiếu trong mọi chiến lược dữ liệu nghiêm túc.\n",
    "\n",
    "Tương tự như nhà phân tích dữ liệu, kỹ sư dữ liệu có thể bắt đầu sự nghiệp từ các vị trí cơ bản như:\n",
    "\n",
    "-   Junior Data Engineer\n",
    "-   Data Engineer\n",
    "-   Senior Data Engineer\n",
    "-   Principal Data Engineer\n",
    "-   Data Engineering Manager/Architect\n",
    "\n",
    "Quá trình thăng tiến thường gắn liền với việc nắm vững các nền tảng hạ tầng dữ liệu, mở rộng phạm vi hệ thống phụ trách, khả năng thiết kế pipeline phức tạp hơn, và năng lực phối hợp với các nhóm khác như chuyên gia dữ liệu, chuyên gia an toàn thông tin.\n",
    "\n",
    "Ở cấp độ cao hơn, kỹ sư dữ liệu không chỉ thực thi mà còn định hình chiến lược hạ tầng dữ liệu, đề xuất kiến trúc tổng thể, lựa chọn công nghệ phù hợp, và dẫn dắt nhóm kỹ thuật đảm bảo tính ổn định và bảo mật của toàn bộ chu trình xử lý dữ liệu.\n",
    "\n",
    "Kỹ năng của một kỹ sư dữ liệu bao gồm ba nhóm chính:\n",
    "\n",
    "-   **Kỹ thuật nền tảng**:\n",
    "    -   Làm việc với cơ sở dữ liệu quan hệ (SQL Server, PostgreSQL, MySQL) và phi quan hệ (MongoDB, Cassandra).\n",
    "    -   Thiết kế pipeline xử lý dữ liệu sử dụng các công cụ như Apache Spark, Kafka, Airflow, DBT.\n",
    "    -   Làm việc với hệ thống phân tán: Hadoop, Hive, EMR.\n",
    "    -   Kỹ năng lập trình mạnh mẽ với các ngôn ngữ như Python, Scala, Java.\n",
    "-   **Kiến trúc dữ liệu và hệ thống**:\n",
    "    -   Thiết kế hệ thống ETL/ELT bền vững và có khả năng mở rộng.\n",
    "    -   Làm việc với data warehouse (Redshift, Snowflake, BigQuery) và data lake.\n",
    "    -   Hiểu biết về hạ tầng cloud (AWS, Azure, GCP) và triển khai dữ liệu trên cloud-native architecture.\n",
    "-   **Kỹ năng liên ngành và phối hợp**:\n",
    "    -   Khả năng làm việc với nhóm phân tích dữ liệu, khoa học dữ liệu và nghiệp vụ để hiểu yêu cầu dữ liệu đầu cuối.\n",
    "    -   Kỹ năng quản lý phiên bản dữ liệu, lập lịch pipeline, kiểm thử và giám sát chất lượng dữ liệu.\n",
    "    -   Kiến thức về bảo mật, kiểm soát truy cập, và tuân thủ các quy định về dữ liệu (GDPR, HIPAA...).\n",
    "        \n",
    "Trong bối cảnh dữ liệu trở thành tài sản chiến lược, kỹ sư dữ liệu chính là người xây dựng nền móng cho các hoạt động phân tích, ra quyết định, học máy và AI.\n",
    "Dù ít xuất hiện trong các bản trình bày trực tiếp như nhà phân tích hoặc nhà khoa học dữ liệu, kỹ sư dữ liệu là người bảo đảm chất lượng và tính sẵn sàng của dữ liệu – yếu tố quyết định sự thành công của bất kỳ dự án dữ liệu nào.\n",
    "Sự phát triển nhanh chóng của công nghệ, đặc biệt là hệ sinh thái dữ liệu đám mây, kiến trúc hướng dịch vụ, và phân tích thời gian thực, đang mở ra nhiều cơ hội mới cho những kỹ sư dữ liệu có năng lực và khát vọng vươn xa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f021ca0f-f345-4b01-8fcf-2acffcfc940f",
   "metadata": {},
   "source": [
    "### Chuyên gia dữ liệu\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa1b4d0-2289-4bf3-904e-2ba3f7d23e88",
   "metadata": {},
   "source": [
    "Chuyên gia dữ liệu là một trong những vị trí có ảnh hưởng lớn nhất trong hệ sinh thái dữ liệu hiện đại, đóng vai trò chuyển hóa dữ liệu phức tạp thành thông tin có thể hành động được thông qua sự kết hợp giữa lập trình, thống kê, mô hình học máy và hiểu biết nghiệp vụ.\n",
    "Họ là người kết nối giữa dữ liệu và ra quyết định chiến lược, đồng thời đóng vai trò trung gian giữa kỹ thuật và kinh doanh.\n",
    "\n",
    "Khác với kỹ sư dữ liệu – người xây dựng hạ tầng và pipeline dữ liệu – và nhà phân tích dữ liệu – người diễn giải dữ liệu hiện có để tạo báo cáo, chuyên gia dữ liệu là người đặt ra câu hỏi, xây dựng mô hình dự đoán, khám phá mối quan hệ ẩn và đề xuất giải pháp dựa trên dữ liệu.\n",
    "Vì vậy, họ thường được kỳ vọng có tư duy phản biện, khả năng phân tích sâu sắc, và năng lực xây dựng mô hình phức tạp phục vụ cho các mục tiêu như tối ưu hóa, phân đoạn khách hàng, phát hiện gian lận, dự báo nhu cầu...\n",
    "\n",
    "Con đường nghề nghiệp của chuyên gia dữ liệu thường bao gồm:\n",
    "\n",
    "-   Junior Data Scientis\n",
    "-   Applied Data Scientist\n",
    "-   Senior / Lead Data Scientist\n",
    "-   Principal Data Scientist / AI Scientist\n",
    "-   Data Science Manager / Director of Data Science\n",
    "\n",
    "Khác với nhiều nghề kỹ thuật khác, lộ trình phát triển của chuyên gia dữ liệu đòi hỏi sự tiến hóa cả về chiều sâu kỹ thuật, mức độ mô hình hóa, và tầm nhìn nghiệp vụ.\n",
    "Ở các cấp bậc cao hơn, chuyên gia dữ liệu không chỉ tập trung vào thuật toán mà còn dẫn dắt chiến lược dữ liệu, đóng góp vào định hướng sản phẩm và chính sách ra quyết định của tổ chức.\n",
    "\n",
    "Năng lực cốt lõi của chuyên gia dữ liệu bao gồm có\n",
    "\n",
    "-   **Năng lực phân tích và mô hình hóa**: làm chủ các kỹ thuật học máy có giám sát và không giám sát: hồi quy, phân loại, phân cụm, cây quyết định, random forest, boosting, SVM, deep learning...\n",
    "    Đồng thời có khả năng ưng dụng thống kê suy luận để thiết lập kiểm định, tính xác suất, ước lượng sai số, và chọn mô hình.\n",
    "\n",
    "-   **Kỹ năng kỹ thuật và công cụ**:\n",
    "\n",
    "    -   Sử dụng thành thạo Python hoặc R, cùng với các thư viện như Scikit-learn, TensorFlow, Keras, PyTorch, Pandas, NumPy.\n",
    "    -   Trực quan hóa dữ liệu với Matplotlib, Seaborn, Plotly hoặc ggplot2.\n",
    "    -   Thành thạo SQL và thao tác với dữ liệu lớn (Spark, Hadoop).\n",
    "    -   Khả năng xây dựng pipeline phân tích, tái sử dụng mô hình và triển khai mô hình (MLOps).\n",
    "\n",
    "-   **Năng lực kinh doanh và truyền thông**:\n",
    "\n",
    "    -   Hiểu biết sâu về lĩnh vực ứng dụng: tài chính, chăm sóc sức khỏe, tiếp thị, logistics, công nghiệp...\n",
    "    -   Kỹ năng giải thích mô hình cho người không chuyên và đưa ra khuyến nghị dựa trên dữ liệu.\n",
    "    -   Kỹ năng kể chuyện bằng dữ liệu (data storytelling) và truyền đạt thông tin rõ ràng, thuyết phục.\n",
    "\n",
    "Chuyên gia dữ liệu ngày nay không chỉ là “kỹ sư thống kê” hiện đại, mà là người định hình quyết định chiến lược dựa trên dữ liệu, là cầu nối giữa trí tuệ nhân tạo (AI) và ứng dụng thực tiễn.\n",
    "Trong các tổ chức đổi mới, chuyên gia dữ liệu tham gia cả vào quy trình phát triển sản phẩm, cải tiến vận hành, thiết kế hệ thống khuyến nghị, và dự báo hành vi người dùng.\n",
    "Theo báo cáo của LinkedIn và Harvard Business Review, Data Scientist liên tục nằm trong top những nghề nghiệp được săn đón và có mức thu nhập cao nhất trong kỷ nguyên số.\n",
    "Với sự phát triển của các lĩnh vực như AI, phân tích dự báo, tối ưu hóa vận hành, và sản phẩm thông minh, triển vọng nghề nghiệp cho chuyên gia dữ liệu tiếp tục mở rộng và đa dạng hóa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
